{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- starting point of Episode 0 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 0 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d01990>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d27790>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d365c0>, <__main__.Case object at 0x7973e1d374c0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d4bb50>, <__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5d090>, <__main__.Case object at 0x7973e1d5dae0>, <__main__.Case object at 0x7973e1d5e440>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d36470>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3fe80>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d4a1a0>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d52c20>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5cfa0>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d5df30>, <__main__.Case object at 0x7973e1d5ea40>]\n",
      "agent1 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Episode: 0, Total Steps: 28, Total Rewards: [-37, -33], Status Episode: False\n",
      "------------------------------------------End of episode 0 loop--------------------\n",
      "----- starting point of Episode 1 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 1 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d27790>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d246a0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d26980>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5dae0>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d34790>, <__main__.Case object at 0x7973e1d36470>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d4bb50>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d51930>, <__main__.Case object at 0x7973e1d52c20>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d02d40>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5e9e0>, <__main__.Case object at 0x7973e1d5d090>, <__main__.Case object at 0x7973e1d5c520>]\n",
      "agent1 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Episode: 1, Total Steps: 24, Total Rewards: [-33, -11], Status Episode: False\n",
      "------------------------------------------End of episode 1 loop--------------------\n",
      "----- starting point of Episode 2 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 2 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d246a0>, <__main__.Case object at 0x7973e1d27880>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d51930>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d34790>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5e980>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d5ea40>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5ed40>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d5eef0>, <__main__.Case object at 0x7973e1d5f040>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d5f250>, <__main__.Case object at 0x7973e1d5e530>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d3fe80>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d4bb50>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d52c20>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d365c0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5dae0>, <__main__.Case object at 0x7973e1d5e9e0>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5ecb0>, <__main__.Case object at 0x7973e1d5ed70>, <__main__.Case object at 0x7973e1d5edd0>, <__main__.Case object at 0x7973e1d5ee60>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5f400>, <__main__.Case object at 0x7973e1d5db10>]\n",
      "agent1 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Episode: 2, Total Steps: 35, Total Rewards: [-44, -43], Status Episode: False\n",
      "------------------------------------------End of episode 2 loop--------------------\n",
      "----- starting point of Episode 3 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 3 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d52c20>, <__main__.Case object at 0x7973e1d02d40>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d3fe80>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3dcf0>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d26980>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d5e8f0>]\n",
      "agent1 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Episode: 3, Total Steps: 22, Total Rewards: [-31, -15], Status Episode: False\n",
      "------------------------------------------End of episode 3 loop--------------------\n",
      "----- starting point of Episode 4 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 4 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d34790>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d27880>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d5fbe0>, <__main__.Case object at 0x7973e1d5ec20>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d5ee30>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5ecb0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d5e9e0>, <__main__.Case object at 0x7973e1d5f160>, <__main__.Case object at 0x7973e1d5ef20>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d5f010>, <__main__.Case object at 0x7973e1d5e980>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5fa30>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d5f7f0>]\n",
      "agent0 comm temp case base: []\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d36470>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d246a0>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d5db10>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5fb50>, <__main__.Case object at 0x7973e1d5f2b0>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5edd0>, <__main__.Case object at 0x7973e1d5ed70>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5dae0>, <__main__.Case object at 0x7973e1d5f280>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5eef0>, <__main__.Case object at 0x7973e1d5ed10>, <__main__.Case object at 0x7973e1d5e920>, <__main__.Case object at 0x7973e1d5d630>, <__main__.Case object at 0x7973e1d5faf0>, <__main__.Case object at 0x7973e1d5fa00>, <__main__.Case object at 0x7973e1d5f910>, <__main__.Case object at 0x7973e1d5f8e0>, <__main__.Case object at 0x7973e1d5f7c0>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5f640>]\n",
      "agent1 comm temp case base: []\n",
      "Episode succeeded, case (4, 3) is empty. Temporary case base stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 0, 0.5)\n",
      "Episode succeeded, case (3, 3) is empty. Temporary case base stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) is empty. Temporary case base stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 1, 0.5)\n",
      "Episode succeeded, case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 1, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 1, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 0, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((0, 0), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 3, 0.5)\n",
      "Episode succeeded, case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 0, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 0, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 1, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 0, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 1, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 0, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 2), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 2), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5\n",
      "Episode: 4, Total Steps: 42, Total Rewards: [-26, 9], Status Episode: False\n",
      "------------------------------------------End of episode 4 loop--------------------\n",
      "----- starting point of Episode 5 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.5, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 0.5, 8, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 0.5, 15, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 0.5, 31, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 0.5, 35, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 0.5, 36, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.5, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.5, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 0.5, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 0.5, 41, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 5 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 5 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d5fbb0>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5ec20>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d5ea40>, <__main__.Case object at 0x7973e1d5f8b0>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d5f5b0>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5ff70>, <__main__.Case object at 0x7973e1d3efb0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d4bb50>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d34790>, <__main__.Case object at 0x7973e1d52c20>, <__main__.Case object at 0x7973e1d27790>]\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (4, 3) is empty. Temporary case base stored to the case base: ((4, 3), 2, 0.5)\n",
      "Integrated case process. comm case (3, 3) is empty. Temporary case base stored to the case base: ((3, 3), 4, 0.5)\n",
      "Integrated case process. comm case (3, 2) is empty. Temporary case base stored to the case base: ((3, 2), 2, 0.5)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 0.5)\n",
      "Integrated case process. comm case (2, 1) is empty. Temporary case base stored to the case base: ((2, 1), 4, 0.5)\n",
      "Integrated case process. comm case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5eb90>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d5f040>, <__main__.Case object at 0x7973e1d5f010>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5f790>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5f250>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5fee0>, <__main__.Case object at 0x7973e1d5ff10>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5fe80>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 0.6, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 0.6, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.6, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 0.6, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 4, tv: 0.09999999999999998, time steps: 33\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 1, tv: 0.09999999999999998, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 1, tv: 0.09999999999999998, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.09999999999999998, time steps: 21\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.6, time steps: 4\n",
      "Episode succeeded, case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.5\n",
      "Episode: 5, Total Steps: 33, Total Rewards: [-42, 41], Status Episode: False\n",
      "------------------------------------------End of episode 5 loop--------------------\n",
      "----- starting point of Episode 6 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.6, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 0.6, 8, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 0.6, 15, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 0.6, 31, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 0.6, 35, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 0.6, 36, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.6, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 6 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.6, 38, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.5, 31, None)\n",
      "----- starting point of Episode 6 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 0.6, 39, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.5, 35, None)\n",
      "----- starting point of Episode 6 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 0.6, 41, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.5, 36, None)\n",
      "----- starting point of Episode 6 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.5, 32, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.5, 36, None)\n",
      "----- starting point of Episode 6 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.5, 32, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.5, 36, None)\n",
      "----- starting point of Episode 6 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.5, 32, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.5, 36, None)\n",
      "----- starting point of Episode 6 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.5, 32, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.5, 36, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5ea40>, <__main__.Case object at 0x7973e1d5ed70>, <__main__.Case object at 0x7973e1d5feb0>, <__main__.Case object at 0x7973e1d5fa90>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5f670>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5fe20>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.6, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.6, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.6, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 0.6, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.6, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.09999999999999998, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.09999999999999998, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.09999999999999998, time steps: 4\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d5fb50>, <__main__.Case object at 0x7973e1d5e9e0>, <__main__.Case object at 0x7973e1d5f8b0>, <__main__.Case object at 0x7973e1d5dae0>, <__main__.Case object at 0x7973e1d5ff70>, <__main__.Case object at 0x7973e1d5eb90>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d5fbb0>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5f130>, <__main__.Case object at 0x7973e1d5f370>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 0.7, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 0.7, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.7, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 0.7, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.7, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.7, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 0.7, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 0.7, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.7, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "Episode: 6, Total Steps: 14, Total Rewards: [37, 41], Status Episode: True\n",
      "------------------------------------------End of episode 6 loop--------------------\n",
      "----- starting point of Episode 7 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.7, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 6, None)\n",
      "----- starting point of Episode 7 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 0.7, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.6, 31, None)\n",
      "----- starting point of Episode 7 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 0.7, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.6, 35, None)\n",
      "----- starting point of Episode 7 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 0.7, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.6, 36, None)\n",
      "----- starting point of Episode 7 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 0.7, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.6, 37, None)\n",
      "----- starting point of Episode 7 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 0.7, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.6, 38, None)\n",
      "----- starting point of Episode 7 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.7, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 0.6, 39, None)\n",
      "----- starting point of Episode 7 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.7, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 0.6, 41, None)\n",
      "----- starting point of Episode 7 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.7, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.5, 32, None)\n",
      "----- starting point of Episode 7 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.7, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.5, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5ecb0>, <__main__.Case object at 0x7973e1d5c070>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d341f0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.7, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.7, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.7, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.7, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 0.7, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.7, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.7, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 1, tv: 0.09999999999999998, time steps: 5\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 0.7)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 0.7)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 0.7)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d5fa60>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d5ef50>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5c6a0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 0.7999999999999999, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 0.7999999999999999, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.7999999999999999, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.7999999999999999, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 0.7999999999999999, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.7999999999999999, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.7999999999999999, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 0.7999999999999999, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 0.7999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.7999999999999999, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "Episode: 7, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 7 loop--------------------\n",
      "----- starting point of Episode 8 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.7999999999999999, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 6, None)\n",
      "----- starting point of Episode 8 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 0.7999999999999999, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.7, 31, None)\n",
      "----- starting point of Episode 8 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 0.7999999999999999, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.7, 35, None)\n",
      "----- starting point of Episode 8 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 0.7999999999999999, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.7, 36, None)\n",
      "----- starting point of Episode 8 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 0.7999999999999999, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.7, 37, None)\n",
      "----- starting point of Episode 8 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 0.7999999999999999, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.7, 38, None)\n",
      "----- starting point of Episode 8 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.7999999999999999, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 0.7, 39, None)\n",
      "----- starting point of Episode 8 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.7999999999999999, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 0.7, 41, None)\n",
      "----- starting point of Episode 8 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.7999999999999999, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "----- starting point of Episode 8 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.7999999999999999, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d5fa60>, <__main__.Case object at 0x7973e1d5ee00>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d5eda0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.7999999999999999, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.7999999999999999, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.7999999999999999, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.7999999999999999, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 0.7999999999999999, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.7999999999999999, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.7999999999999999, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.7, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.29999999999999993, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.29999999999999993, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.29999999999999993, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d5f130>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5f5b0>, <__main__.Case object at 0x7973e1d5ec50>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5ea40>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5f250>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 0.8999999999999999, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 0.8999999999999999, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.8999999999999999, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.8999999999999999, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 0.8999999999999999, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.8999999999999999, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.8999999999999999, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 0.8999999999999999, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 0.8999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.8999999999999999, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.09999999999999998, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 0.6)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "Episode: 8, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 8 loop--------------------\n",
      "----- starting point of Episode 9 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.8999999999999999, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7, 6, None)\n",
      "----- starting point of Episode 9 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 0.8999999999999999, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.7999999999999999, 31, None)\n",
      "----- starting point of Episode 9 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 0.8999999999999999, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.7999999999999999, 35, None)\n",
      "----- starting point of Episode 9 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 0.8999999999999999, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.7999999999999999, 36, None)\n",
      "----- starting point of Episode 9 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 0.8999999999999999, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.7999999999999999, 37, None)\n",
      "----- starting point of Episode 9 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 0.8999999999999999, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.7999999999999999, 38, None)\n",
      "----- starting point of Episode 9 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.8999999999999999, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 0.7999999999999999, 39, None)\n",
      "----- starting point of Episode 9 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.8999999999999999, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 0.7999999999999999, 41, None)\n",
      "----- starting point of Episode 9 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.8999999999999999, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.7, 32, None)\n",
      "----- starting point of Episode 9 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.8999999999999999, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.7, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5fa60>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d34be0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.8999999999999999, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.8999999999999999, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.8999999999999999, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.8999999999999999, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 0.8999999999999999, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.8999999999999999, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.8999999999999999, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.7999999999999999, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.8999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5fbb0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5f670>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 0.9999999999999999, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 0.9999999999999999, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 0.9999999999999999, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.9999999999999999, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 0.9999999999999999, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.9999999999999999, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.9999999999999999, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 0.9999999999999999, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 0.9999999999999999, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.9999999999999999, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.7)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "Episode: 9, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 9 loop--------------------\n",
      "----- starting point of Episode 10 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.9999999999999999, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7999999999999999, 6, None)\n",
      "----- starting point of Episode 10 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 0.9999999999999999, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.8999999999999999, 31, None)\n",
      "----- starting point of Episode 10 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 0.9999999999999999, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.8999999999999999, 35, None)\n",
      "----- starting point of Episode 10 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 0.9999999999999999, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.8999999999999999, 36, None)\n",
      "----- starting point of Episode 10 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 0.9999999999999999, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.8999999999999999, 37, None)\n",
      "----- starting point of Episode 10 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 0.9999999999999999, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.8999999999999999, 38, None)\n",
      "----- starting point of Episode 10 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.9999999999999999, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 0.8999999999999999, 39, None)\n",
      "----- starting point of Episode 10 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.9999999999999999, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 0.8999999999999999, 41, None)\n",
      "----- starting point of Episode 10 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.9999999999999999, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.7999999999999999, 32, None)\n",
      "----- starting point of Episode 10 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 0.9999999999999999, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.7999999999999999, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d5fbb0>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d5ff10>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 0.9999999999999999, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 0.9999999999999999, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 0.9999999999999999, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.9999999999999999, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 0.9999999999999999, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.9999999999999999, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.9999999999999999, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.8999999999999999, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.4999999999999999, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.4999999999999999, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.4999999999999999, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.4999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5fe50>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5c520>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.29999999999999993, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 0.7999999999999999)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.7999999999999999\n",
      "Episode: 10, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 10 loop--------------------\n",
      "----- starting point of Episode 11 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.8999999999999999, 6, None)\n",
      "----- starting point of Episode 11 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.9999999999999999, 31, None)\n",
      "----- starting point of Episode 11 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.9999999999999999, 35, None)\n",
      "----- starting point of Episode 11 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.9999999999999999, 36, None)\n",
      "----- starting point of Episode 11 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.9999999999999999, 37, None)\n",
      "----- starting point of Episode 11 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 0.9999999999999999, 38, None)\n",
      "----- starting point of Episode 11 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 0.9999999999999999, 39, None)\n",
      "----- starting point of Episode 11 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 0.9999999999999999, 41, None)\n",
      "----- starting point of Episode 11 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.8999999999999999, 32, None)\n",
      "----- starting point of Episode 11 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.8999999999999999, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5e8c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.9999999999999999, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.09999999999999987, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.09999999999999987, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.09999999999999987, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.9999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d5f520>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d5e980>, <__main__.Case object at 0x7973e1d5f6d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d5ff10>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5ee00>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.3999999999999999, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "Episode: 11, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 11 loop--------------------\n",
      "----- starting point of Episode 12 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.9999999999999999, 6, None)\n",
      "----- starting point of Episode 12 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 12 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 12 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 12 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 12 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 12 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 12 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 12 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.9999999999999999, 32, None)\n",
      "----- starting point of Episode 12 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 0.9999999999999999, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5e8c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d356f0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5efb0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d5edd0>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5ec50>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.4999999999999999, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 0.9999999999999999)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.9999999999999999\n",
      "Episode: 12, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 12 loop--------------------\n",
      "----- starting point of Episode 13 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 13 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 13 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 13 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 13 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 13 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 13 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 13 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 13 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 13 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5f520>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5fc10>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d5ea40>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d5ff10>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5fac0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d5f670>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5c520>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.09999999999999987, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.5999999999999999, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.5999999999999999\n",
      "Episode: 13, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 13 loop--------------------\n",
      "----- starting point of Episode 14 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 14 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 14 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 14 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 14 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 14 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 14 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 14 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 14 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 14 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5f520>, <__main__.Case object at 0x7973e1d5ff10>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d5f070>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d5f130>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5e8c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5f370>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.19999999999999984, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 14, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 14 loop--------------------\n",
      "----- starting point of Episode 15 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 15 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 15 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 15 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 15 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 15 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 15 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 15 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 15 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 15 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5ff10>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d37ee0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5f550>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d5f790>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d5f6d0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 15, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 15 loop--------------------\n",
      "----- starting point of Episode 16 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 16 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 16 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 16 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 16 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 16 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 16 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 16 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 16 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 16 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5f130>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5ee30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5edd0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5f670>, <__main__.Case object at 0x7973e1d5ee60>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d5ec50>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "Episode: 16, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 16 loop--------------------\n",
      "----- starting point of Episode 17 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 17 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 17 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 17 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 17 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 17 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 17 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 17 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 17 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 17 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5f130>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d5fe50>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5ea40>, <__main__.Case object at 0x7973e1d5ff10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5c520>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 17, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 17 loop--------------------\n",
      "----- starting point of Episode 18 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 18 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 18 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 18 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 18 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 18 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 18 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 18 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 18 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 18 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d03160>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5ece0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d5e8c0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 18, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 18 loop--------------------\n",
      "----- starting point of Episode 19 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 19 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 19 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 19 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 19 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 19 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 19 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 19 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 19 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 19 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5fa30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d5f790>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5f0d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5ee30>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d5f6d0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "Episode: 19, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 19 loop--------------------\n",
      "----- starting point of Episode 20 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 20 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 20 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 20 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 20 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 20 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 20 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 20 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 20 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 20 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5f070>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d5fac0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5edd0>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5ec50>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 20, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 20 loop--------------------\n",
      "----- starting point of Episode 21 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 21 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 21 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 21 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 21 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 21 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 21 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 21 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 21 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 21 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5f070>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d50e80>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5ee60>, <__main__.Case object at 0x7973e1d5fa60>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d5f670>, <__main__.Case object at 0x7973e1d5ee30>, <__main__.Case object at 0x7973e1d5ff10>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 21, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 21 loop--------------------\n",
      "----- starting point of Episode 22 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 22 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 22 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 22 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 22 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 22 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 22 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 22 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 22 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 22 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d50a90>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d5fa60>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5f610>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5f6a0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5fbb0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d5fdf0>, <__main__.Case object at 0x7973e1d5fa30>, <__main__.Case object at 0x7973e1d5ee30>, <__main__.Case object at 0x7973e1d5e8c0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "Episode: 22, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 22 loop--------------------\n",
      "----- starting point of Episode 23 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 23 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 23 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 23 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 23 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 23 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 23 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 23 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 23 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 23 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5fe50>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d5efb0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d5fe80>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5f790>, <__main__.Case object at 0x7973e1d5f070>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5f6d0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 23, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 23 loop--------------------\n",
      "----- starting point of Episode 24 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 24 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 24 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 24 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 24 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 24 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 24 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 24 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 24 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 24 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5ee30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d5fdf0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5c520>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5fe50>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 24, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 24 loop--------------------\n",
      "----- starting point of Episode 25 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 25 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 25 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 25 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 25 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 25 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 25 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 25 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 25 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 25 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d5f790>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5f670>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5fb20>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d5fdf0>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5eb90>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5f580>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "Episode: 25, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 25 loop--------------------\n",
      "----- starting point of Episode 26 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 26 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 26 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 26 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 26 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 26 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 26 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 26 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 26 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 26 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5fdf0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d5e8c0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5f610>, <__main__.Case object at 0x7973e1d5fa60>, <__main__.Case object at 0x7973e1d5ee30>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d5d630>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5fac0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 26, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 26 loop--------------------\n",
      "----- starting point of Episode 27 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 27 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 27 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 27 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 27 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 27 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 27 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 27 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 27 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 27 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5fdf0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5ee00>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5eb90>, <__main__.Case object at 0x7973e1d5c550>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5ece0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 27, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 27 loop--------------------\n",
      "----- starting point of Episode 28 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 28 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 28 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 28 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 28 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 28 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 28 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 28 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 28 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 28 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5eb90>, <__main__.Case object at 0x7973e1d5f130>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d5ffd0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5fb80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5c550>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5fe50>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "Episode: 28, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 28 loop--------------------\n",
      "----- starting point of Episode 29 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 29 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 29 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 29 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 29 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 29 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 29 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 29 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 29 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 29 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5ee00>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d5eb90>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5f670>, <__main__.Case object at 0x7973e1d5f790>, <__main__.Case object at 0x7973e1d5fdf0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5f250>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 29, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 29 loop--------------------\n",
      "----- starting point of Episode 30 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 30 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 30 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 30 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 30 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 30 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 30 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 30 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 30 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 30 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d5ee30>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5ee00>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d5f940>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d5eb90>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5fa30>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5f250>, <__main__.Case object at 0x7973e1d5d9f0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 30, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 30 loop--------------------\n",
      "----- starting point of Episode 31 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 31 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 31 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 31 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 31 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 31 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 31 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 31 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 31 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 31 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5e8f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d5ead0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5c550>, <__main__.Case object at 0x7973e1d5f2e0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5fa30>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5f250>, <__main__.Case object at 0x7973e1d5ece0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "Episode: 31, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 31 loop--------------------\n",
      "----- starting point of Episode 32 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 32 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 32 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 32 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 32 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 32 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 32 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 32 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 32 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 32 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d5f820>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5f940>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d5fb80>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 4\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5f130>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5ee00>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5eb90>, <__main__.Case object at 0x7973e1d5f160>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 32, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 32 loop--------------------\n",
      "----- starting point of Episode 33 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 33 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 33 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 33 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 33 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 1), 4, 1, 35, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 33 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 1), 4, 1, 36, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 33 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "----- starting point of Episode 33 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 33 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "----- starting point of Episode 33 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 4), 1, 1, 32, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d5fdf0>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5f940>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d5f820>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 3, 1)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 3, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 3, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5efb0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5f160>, <__main__.Case object at 0x7973e1d5ecb0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 1, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 1, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 1, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (3, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((2, 0), 3, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 0), 3, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 3, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 33, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 33 loop--------------------\n",
      "----- starting point of Episode 34 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 6, None)\n",
      "----- starting point of Episode 34 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 1, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 1, 31, None)\n",
      "----- starting point of Episode 34 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 1, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 1, 35, None)\n",
      "----- starting point of Episode 34 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 1, 36, None)\n",
      "----- starting point of Episode 34 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "----- starting point of Episode 34 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 1, 31, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 1, 37, None)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3e1d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d269b0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 0.6, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.6, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3ce20>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3f0a0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 0.6, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.6, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.6, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 1), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 34, Total Steps: 6, Total Rewards: [-13, -15], Status Episode: False\n",
      "------------------------------------------End of episode 34 loop--------------------\n",
      "----- starting point of Episode 35 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 3, 0.6, 4, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 6, None)\n",
      "----- starting point of Episode 35 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 0), 3, 0.6, 8, None)\n",
      "comm next state for agent 1: ((1, 0), 2, 0.6, 31, None)\n",
      "----- starting point of Episode 35 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((2, 0), 3, 0.6, 15, None)\n",
      "comm next state for agent 1: ((1, 1), 4, 0.6, 35, None)\n",
      "----- starting point of Episode 35 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 0.6, 31, None)\n",
      "comm next state for agent 1: ((2, 1), 4, 0.6, 36, None)\n",
      "----- starting point of Episode 35 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 0.6, 31, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.6, 37, None)\n",
      "----- starting point of Episode 35 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((1, 0), 2, 0.6, 31, None)\n",
      "comm next state for agent 1: ((3, 1), 2, 0.6, 37, None)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3e5f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d25960>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 4, tv: 0.19999999999999996, time steps: 36\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.19999999999999996, time steps: 31\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 1, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3efb0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3c820>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 1, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (2, 1), solution: 4, tv: 0.19999999999999996, time steps: 36\n",
      "case content after REVISE for agent 1, problem: (1, 1), solution: 4, tv: 0.19999999999999996, time steps: 35\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 2, tv: 0.19999999999999996, time steps: 31\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 3, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 3, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 35, Total Steps: 6, Total Rewards: [-13, -15], Status Episode: False\n",
      "------------------------------------------End of episode 35 loop--------------------\n",
      "----- starting point of Episode 36 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 36 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 48 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 49 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 50 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 51 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 52 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 53 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 54 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 55 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 56 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 57 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 58 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 59 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 60 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 61 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 62 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 63 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 64 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 65 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 66 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 67 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 68 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 69 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 70 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 71 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 72 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 73 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 36 in steps 74 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 1, 37, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5fe80>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5ff10>, <__main__.Case object at 0x7973e1d5eb00>, <__main__.Case object at 0x7973e1d5ebc0>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5f520>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5f820>, <__main__.Case object at 0x7973e1d5ed10>, <__main__.Case object at 0x7973e1d5e9e0>, <__main__.Case object at 0x7973e1d5fa90>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5d090>, <__main__.Case object at 0x7973e1d5f700>, <__main__.Case object at 0x7973e1d5fcd0>, <__main__.Case object at 0x7973e1d5f2b0>, <__main__.Case object at 0x7973e1d5fd60>, <__main__.Case object at 0x7973e1d74160>, <__main__.Case object at 0x7973e1d74280>, <__main__.Case object at 0x7973e1d743a0>, <__main__.Case object at 0x7973e1d744f0>, <__main__.Case object at 0x7973e1d745e0>, <__main__.Case object at 0x7973e1d74700>, <__main__.Case object at 0x7973e1d74820>, <__main__.Case object at 0x7973e1d74790>, <__main__.Case object at 0x7973e1d74a60>, <__main__.Case object at 0x7973e1d74b80>, <__main__.Case object at 0x7973e1d74ca0>, <__main__.Case object at 0x7973e1d74df0>, <__main__.Case object at 0x7973e1d74ee0>, <__main__.Case object at 0x7973e1d75000>, <__main__.Case object at 0x7973e1d75120>, <__main__.Case object at 0x7973e1d75270>, <__main__.Case object at 0x7973e1d75360>, <__main__.Case object at 0x7973e1d75480>, <__main__.Case object at 0x7973e1d755a0>, <__main__.Case object at 0x7973e1d756f0>, <__main__.Case object at 0x7973e1d757e0>, <__main__.Case object at 0x7973e1d75900>, <__main__.Case object at 0x7973e1d75a20>, <__main__.Case object at 0x7973e1d75b70>, <__main__.Case object at 0x7973e1d75c60>, <__main__.Case object at 0x7973e1d75d80>, <__main__.Case object at 0x7973e1d75ea0>, <__main__.Case object at 0x7973e1d75ff0>, <__main__.Case object at 0x7973e1d760e0>, <__main__.Case object at 0x7973e1d76200>, <__main__.Case object at 0x7973e1d76320>, <__main__.Case object at 0x7973e1d76470>, <__main__.Case object at 0x7973e1d76560>, <__main__.Case object at 0x7973e1d76680>, <__main__.Case object at 0x7973e1d767a0>, <__main__.Case object at 0x7973e1d768f0>, <__main__.Case object at 0x7973e1d769e0>, <__main__.Case object at 0x7973e1d76b00>, <__main__.Case object at 0x7973e1d76c20>, <__main__.Case object at 0x7973e1d76d70>, <__main__.Case object at 0x7973e1d76e60>, <__main__.Case object at 0x7973e1d76f80>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5f4c0>, <__main__.Case object at 0x7973e1d5ea70>, <__main__.Case object at 0x7973e1d5dae0>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5eb90>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5fb50>, <__main__.Case object at 0x7973e1d5f5b0>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d5f250>, <__main__.Case object at 0x7973e1d5f040>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d740d0>, <__main__.Case object at 0x7973e1d741f0>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d74310>, <__main__.Case object at 0x7973e1d74550>, <__main__.Case object at 0x7973e1d74670>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d74940>, <__main__.Case object at 0x7973e1d749d0>, <__main__.Case object at 0x7973e1d74af0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d74c10>, <__main__.Case object at 0x7973e1d74e50>, <__main__.Case object at 0x7973e1d74f70>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d75090>, <__main__.Case object at 0x7973e1d752d0>, <__main__.Case object at 0x7973e1d753f0>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d75510>, <__main__.Case object at 0x7973e1d75750>, <__main__.Case object at 0x7973e1d75870>, <__main__.Case object at 0x7973e1d75ab0>, <__main__.Case object at 0x7973e1d75990>, <__main__.Case object at 0x7973e1d75bd0>, <__main__.Case object at 0x7973e1d75cf0>, <__main__.Case object at 0x7973e1d75f30>, <__main__.Case object at 0x7973e1d75e10>, <__main__.Case object at 0x7973e1d76050>, <__main__.Case object at 0x7973e1d76170>, <__main__.Case object at 0x7973e1d763b0>, <__main__.Case object at 0x7973e1d76290>, <__main__.Case object at 0x7973e1d764d0>, <__main__.Case object at 0x7973e1d765f0>, <__main__.Case object at 0x7973e1d76830>, <__main__.Case object at 0x7973e1d76710>, <__main__.Case object at 0x7973e1d76950>, <__main__.Case object at 0x7973e1d76a70>, <__main__.Case object at 0x7973e1d76cb0>, <__main__.Case object at 0x7973e1d76b90>, <__main__.Case object at 0x7973e1d76dd0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.6, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 1, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 1, time steps: 4\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d02d40>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d365c0>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d5fbb0>, <__main__.Case object at 0x7973e1d5ff40>, <__main__.Case object at 0x7973e1d5f670>, <__main__.Case object at 0x7973e1d5d630>, <__main__.Case object at 0x7973e1d5e590>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5eef0>, <__main__.Case object at 0x7973e1d5fa00>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5e980>, <__main__.Case object at 0x7973e1d5ff70>, <__main__.Case object at 0x7973e1d5ee30>, <__main__.Case object at 0x7973e1d5feb0>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5f610>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5cbe0>, <__main__.Case object at 0x7973e1d5e920>, <__main__.Case object at 0x7973e1d5fd00>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d74190>, <__main__.Case object at 0x7973e1d742b0>, <__main__.Case object at 0x7973e1d743d0>, <__main__.Case object at 0x7973e1d74340>, <__main__.Case object at 0x7973e1d74610>, <__main__.Case object at 0x7973e1d74730>, <__main__.Case object at 0x7973e1d74850>, <__main__.Case object at 0x7973e1d747c0>, <__main__.Case object at 0x7973e1d74a90>, <__main__.Case object at 0x7973e1d74bb0>, <__main__.Case object at 0x7973e1d74cd0>, <__main__.Case object at 0x7973e1d74c40>, <__main__.Case object at 0x7973e1d74f10>, <__main__.Case object at 0x7973e1d75030>, <__main__.Case object at 0x7973e1d75150>, <__main__.Case object at 0x7973e1d750c0>, <__main__.Case object at 0x7973e1d75390>, <__main__.Case object at 0x7973e1d754b0>, <__main__.Case object at 0x7973e1d755d0>, <__main__.Case object at 0x7973e1d75540>, <__main__.Case object at 0x7973e1d75810>, <__main__.Case object at 0x7973e1d75930>, <__main__.Case object at 0x7973e1d75a50>, <__main__.Case object at 0x7973e1d759c0>, <__main__.Case object at 0x7973e1d75c90>, <__main__.Case object at 0x7973e1d75db0>, <__main__.Case object at 0x7973e1d75ed0>, <__main__.Case object at 0x7973e1d75e40>, <__main__.Case object at 0x7973e1d76110>, <__main__.Case object at 0x7973e1d76230>, <__main__.Case object at 0x7973e1d76350>, <__main__.Case object at 0x7973e1d762c0>, <__main__.Case object at 0x7973e1d76590>, <__main__.Case object at 0x7973e1d766b0>, <__main__.Case object at 0x7973e1d767d0>, <__main__.Case object at 0x7973e1d76740>, <__main__.Case object at 0x7973e1d76a10>, <__main__.Case object at 0x7973e1d76b30>, <__main__.Case object at 0x7973e1d76c50>, <__main__.Case object at 0x7973e1d76bc0>, <__main__.Case object at 0x7973e1d76e90>, <__main__.Case object at 0x7973e1d76fb0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 36, Total Steps: 75, Total Rewards: [-84, -17], Status Episode: False\n",
      "------------------------------------------End of episode 36 loop--------------------\n",
      "----- starting point of Episode 37 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 37 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d02d40>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d3fe80>, <__main__.Case object at 0x7973e1d5f4f0>, <__main__.Case object at 0x7973e1d5e080>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5fb50>, <__main__.Case object at 0x7973e1d5f130>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d5f040>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5ee60>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d5eb00>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5fbe0>, <__main__.Case object at 0x7973e1d3e5f0>]\n",
      "agent0 comm temp case base: []\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 3, tv: 0.19999999999999996, time steps: 15\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.6, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.6, time steps: 37\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (2, 3) is empty. Temporary case base stored to the case base: ((2, 3), 1, 0.5)\n",
      "Episode succeeded, case (2, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 3), 0, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 1) is empty. Temporary case base stored to the case base: ((2, 1), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 1, 0.5)\n",
      "Episode succeeded, case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 1) is empty. Temporary case base stored to the case base: ((1, 1), 2, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 1, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 0, 0.5)\n",
      "Episode succeeded, case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 0, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 1, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 3, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 0, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 1, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 0, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 3, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 1, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 0, 0.5)\n",
      "Episode succeeded, case (2, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 1), 3, 0.5)\n",
      "Episode succeeded, case (1, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 3, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 3), solution: 1, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 2, tv: 0.5\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d5ea70>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5f5b0>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5f400>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5c550>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5f790>, <__main__.Case object at 0x7973e1d5f8b0>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5df30>, <__main__.Case object at 0x7973e1d5fa90>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "Episode: 37, Total Steps: 33, Total Rewards: [18, -34], Status Episode: False\n",
      "------------------------------------------End of episode 37 loop--------------------\n",
      "----- starting point of Episode 38 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 0), 2, 0.5, 17, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 1), 2, 0.5, 18, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 2), 4, 0.5, 19, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.5, 23, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((2, 2), 4, 0.5, 29, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "----- starting point of Episode 38 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 38 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from case base: 1\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 4), 1, 0.6, 32, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5ff10>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5f5b0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5ead0>]\n",
      "agent0 comm temp case base: []\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.7, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 3, tv: 0.19999999999999996, time steps: 8\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 3, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (2, 3), solution: 1, tv: 0.09999999999999998, time steps: 28\n",
      "case content after REVISE for agent 0, problem: (2, 1), solution: 2, tv: 0.09999999999999998, time steps: 25\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (1, 1), solution: 2, tv: 0.09999999999999998, time steps: 22\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 2, tv: 0.09999999999999998, time steps: 9\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d365c0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5ef20>, <__main__.Case object at 0x7973e1d5fa90>, <__main__.Case object at 0x7973e1d5f0a0>, <__main__.Case object at 0x7973e1d5ee60>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d5f6d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5ebc0>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5c550>, <__main__.Case object at 0x7973e1d5f8b0>, <__main__.Case object at 0x7973e1d5ed10>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.6, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 0.5)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 0.5)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 0.5)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.5\n",
      "Episode: 38, Total Steps: 17, Total Rewards: [43, -26], Status Episode: False\n",
      "------------------------------------------End of episode 38 loop--------------------\n",
      "----- starting point of Episode 39 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 0), 2, 0.6, 17, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 39 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 1), 2, 0.6, 18, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 39 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 2), 4, 0.6, 19, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 39 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 23, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 39 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((2, 2), 4, 0.6, 29, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 39 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.6, 37, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.6, 29, None)\n",
      "----- starting point of Episode 39 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.6, 37, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.6, 29, None)\n",
      "----- starting point of Episode 39 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 1), 2, 0.6, 37, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.6, 29, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d26dd0>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d536d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d365c0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.29999999999999993, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.7, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.7, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 0.7, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.7, time steps: 17\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 1) is empty. Temporary case base stored to the case base: ((3, 1), 2, 0.6)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (3, 1), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d5fac0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d02d40>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d52800>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.5, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.5, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.5, time steps: 18\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 0.6)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 39, Total Steps: 8, Total Rewards: [43, -14], Status Episode: False\n",
      "------------------------------------------End of episode 39 loop--------------------\n",
      "----- starting point of Episode 40 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 0), 2, 0.7, 17, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 40 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 1), 2, 0.7, 18, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 40 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 2), 4, 0.7, 19, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 40 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.7, 23, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 40 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((2, 2), 4, 0.7, 29, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 40 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 40 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 40 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 40 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 40 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d34be0>]\n",
      "agent0 comm temp case base: []\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.7999999999999999, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.7999999999999999, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 0.7999999999999999, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.7999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (3, 1), solution: 2, tv: 0.19999999999999996, time steps: 37\n",
      "Episode succeeded, case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 2, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 2, tv: 0.5\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d24b80>, <__main__.Case object at 0x7973e1d5ed10>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d5e890>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d25b10>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.5, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.5, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.5, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 40, Total Steps: 10, Total Rewards: [43, -19], Status Episode: False\n",
      "------------------------------------------End of episode 40 loop--------------------\n",
      "----- starting point of Episode 41 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 0), 2, 0.7999999999999999, 17, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 1), 2, 0.7999999999999999, 18, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 2), 4, 0.7999999999999999, 19, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 hit the obstacle!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.7999999999999999, 23, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.7999999999999999, 23, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.7999999999999999, 23, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.7999999999999999, 23, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 41 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.7999999999999999, 23, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d03c40>, <__main__.Case object at 0x7973e1d365c0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3ebf0>]\n",
      "agent0 comm temp case base: []\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.8999999999999999, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.8999999999999999, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 0.8999999999999999, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.8999999999999999, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 2, tv: 0.09999999999999998, time steps: 9\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.8999999999999999\n",
      "win status of agent 1  before update the case base: False\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d5fdf0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d24a60>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.5, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.5, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.5, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.5, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 41, Total Steps: 8, Total Rewards: [43, -13], Status Episode: False\n",
      "------------------------------------------End of episode 41 loop--------------------\n",
      "----- starting point of Episode 42 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 0), 2, 0.8999999999999999, 17, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 1), 2, 0.8999999999999999, 18, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((0, 2), 4, 0.8999999999999999, 19, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((1, 2), 4, 0.8999999999999999, 23, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((2, 2), 4, 0.8999999999999999, 29, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from problem solver: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: ((3, 3), 4, 1, 39, None)\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 42 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((4, 3), 2, 1, 41, None)\n",
      "----- starting point of Episode 42 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [True, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 42 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: True\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5ebf0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d52710>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.9999999999999999, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.9999999999999999, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 0.9999999999999999, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.9999999999999999, time steps: 17\n",
      "Episode succeeded, case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 3, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 3, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d02d40>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d37490>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d264d0>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5db10>, <__main__.Case object at 0x7973e1d5fc40>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d269b0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.09999999999999998, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.09999999999999998, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.09999999999999998, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.09999999999999998, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 0, 0.5)\n",
      "Episode succeeded, case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 0, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 4, 0.5)\n",
      "Episode succeeded, case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.5\n",
      "Episode: 42, Total Steps: 10, Total Rewards: [43, 41], Status Episode: True\n",
      "------------------------------------------End of episode 42 loop--------------------\n",
      "----- starting point of Episode 43 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 0.5, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 0.9999999999999999, 17, None)\n",
      "----- starting point of Episode 43 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 0.5, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 0.9999999999999999, 18, None)\n",
      "----- starting point of Episode 43 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 0.5, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 0.9999999999999999, 19, None)\n",
      "----- starting point of Episode 43 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.9999999999999999, 23, None)\n",
      "----- starting point of Episode 43 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 0.9999999999999999, 29, None)\n",
      "----- starting point of Episode 43 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 43 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.6, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 43 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.6, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d5e890>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d27ca0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 3, tv: 0.09999999999999998, time steps: 9\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 0.5)\n",
      "Integrated case process. comm case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 0.5)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.5\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5ee60>, <__main__.Case object at 0x7973e1d5f520>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d5fc40>, <__main__.Case object at 0x7973e1d5c6a0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.7, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 0.9999999999999999)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 0.9999999999999999)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 0.9999999999999999)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.9999999999999999\n",
      "Episode: 43, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 43 loop--------------------\n",
      "----- starting point of Episode 44 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 0.6, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 44 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 0.6, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 44 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 0.6, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 44 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 44 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 44 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 44 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.7, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 44 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.7, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d5e530>, <__main__.Case object at 0x7973e1d5db10>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5f4c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d5d630>, <__main__.Case object at 0x7973e1d5fdc0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.09999999999999998, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.09999999999999998, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.09999999999999998, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 0.7)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5f2b0>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5f8b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d5f520>, <__main__.Case object at 0x7973e1d5f5b0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5ec50>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.7999999999999999, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 0.7, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 0.7, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 0.7, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.5999999999999999, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.5999999999999999, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.5999999999999999, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.5999999999999999, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.5999999999999999, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.5999999999999999\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.5999999999999999\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.5999999999999999\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.5999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.5999999999999999\n",
      "Episode: 44, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 44 loop--------------------\n",
      "----- starting point of Episode 45 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 0.7, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 45 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 0.7, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 45 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 0.7, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 45 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 45 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 45 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 45 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.7999999999999999, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 45 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.7999999999999999, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5f4c0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d5db10>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.29999999999999993, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 0.7)\n",
      "Integrated case process. comm case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 0.7)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 0.7)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.7\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5e9b0>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5fc40>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5e530>, <__main__.Case object at 0x7973e1d5f220>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.8999999999999999, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 0.7999999999999999, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 0.7999999999999999, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 0.7999999999999999, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.19999999999999984, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999984, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.19999999999999984, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.19999999999999984, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999984, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.7999999999999999\n",
      "Episode: 45, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 45 loop--------------------\n",
      "----- starting point of Episode 46 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 0.7999999999999999, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 46 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 0.7999999999999999, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 46 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 0.7999999999999999, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 46 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 46 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 46 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 46 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.8999999999999999, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 46 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.8999999999999999, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5f520>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d5f5b0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.29999999999999993, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.29999999999999993, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.29999999999999993, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.8999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5e530>, <__main__.Case object at 0x7973e1d5f8b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5eaa0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.9999999999999999, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 0.8999999999999999, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 0.8999999999999999, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 0.8999999999999999, time steps: 1\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 46, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 46 loop--------------------\n",
      "----- starting point of Episode 47 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 0.8999999999999999, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 47 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 0.8999999999999999, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 47 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 0.8999999999999999, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 47 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 47 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 47 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 47 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.9999999999999999, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 47 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 0.9999999999999999, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d5d630>, <__main__.Case object at 0x7973e1d5db10>, <__main__.Case object at 0x7973e1d5c520>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5e530>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.4999999999999999, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 0.8999999999999999)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.8999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5fa00>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5f9d0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 0.9999999999999999, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 0.9999999999999999, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 0.9999999999999999, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 47, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 47 loop--------------------\n",
      "----- starting point of Episode 48 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 0.9999999999999999, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 48 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 0.9999999999999999, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 48 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 0.9999999999999999, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 48 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 48 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 48 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 48 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 48 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5eb30>, <__main__.Case object at 0x7973e1d5f520>, <__main__.Case object at 0x7973e1d5f8b0>, <__main__.Case object at 0x7973e1d5ffd0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5f0d0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.09999999999999987, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.4999999999999999, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.4999999999999999, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.4999999999999999, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.4999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5d630>, <__main__.Case object at 0x7973e1d5fc40>, <__main__.Case object at 0x7973e1d5ea70>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d5fa00>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5c550>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "Episode: 48, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 48 loop--------------------\n",
      "----- starting point of Episode 49 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 49 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 49 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 49 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 49 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 49 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 49 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 49 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5eb30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d5fdc0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.09999999999999987, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.09999999999999987, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.09999999999999987, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5c550>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5ec50>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d5fa00>, <__main__.Case object at 0x7973e1d5fac0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 49, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 49 loop--------------------\n",
      "----- starting point of Episode 50 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 50 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 50 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 50 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 50 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 50 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 50 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 50 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5ff70>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d5f9d0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 1)\n",
      "Integrated case process. comm case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d5fa00>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5f490>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5c550>, <__main__.Case object at 0x7973e1d5efb0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 50, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 50 loop--------------------\n",
      "----- starting point of Episode 51 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 51 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 51 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 51 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 51 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 51 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 51 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 51 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5eb30>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5fb20>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5ead0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5ea70>, <__main__.Case object at 0x7973e1d5f2b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5ee60>, <__main__.Case object at 0x7973e1d5fa00>, <__main__.Case object at 0x7973e1d5e590>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "Episode: 51, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 51 loop--------------------\n",
      "----- starting point of Episode 52 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 52 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 52 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 52 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 52 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 52 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 52 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 52 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d5fa30>, <__main__.Case object at 0x7973e1d5c6a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d5ee60>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d5e590>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5c070>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5f580>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 52, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 52 loop--------------------\n",
      "----- starting point of Episode 53 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 53 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 53 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 53 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 53 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 53 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 53 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 53 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d5fa00>, <__main__.Case object at 0x7973e1d5f160>, <__main__.Case object at 0x7973e1d5f7f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d5efb0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 1)\n",
      "Integrated case process. comm case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5ffd0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5e590>, <__main__.Case object at 0x7973e1d5c520>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 53, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 53 loop--------------------\n",
      "----- starting point of Episode 54 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 54 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 54 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 54 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 54 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 54 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 54 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 54 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5ebc0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d5f400>, <__main__.Case object at 0x7973e1d5f0d0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5fa00>, <__main__.Case object at 0x7973e1d5f2b0>, <__main__.Case object at 0x7973e1d5e980>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5f8b0>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5fe20>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "Episode: 54, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 54 loop--------------------\n",
      "----- starting point of Episode 55 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 55 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 55 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 55 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 55 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 55 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 55 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 55 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d5f4c0>, <__main__.Case object at 0x7973e1d5f190>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d5f8b0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d5fe20>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5fa30>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 55, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 55 loop--------------------\n",
      "----- starting point of Episode 56 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 56 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 56 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 56 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 56 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 56 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 56 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 56 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5f370>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d5c520>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 1)\n",
      "Integrated case process. comm case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5f9d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5fe20>, <__main__.Case object at 0x7973e1d5eaa0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 56, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 56 loop--------------------\n",
      "----- starting point of Episode 57 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 57 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 57 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 57 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 57 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 57 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 57 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 57 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5fa30>, <__main__.Case object at 0x7973e1d5d630>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5ead0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5e980>, <__main__.Case object at 0x7973e1d5ed40>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5ff70>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5f5b0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "Episode: 57, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 57 loop--------------------\n",
      "----- starting point of Episode 58 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 58 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 58 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 58 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 58 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 58 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 58 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 58 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5fb20>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d5ff70>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d5f5b0>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5f4c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5f400>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 58, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 58 loop--------------------\n",
      "----- starting point of Episode 59 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 59 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 59 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 59 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 59 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 59 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 59 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 59 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5ef80>, <__main__.Case object at 0x7973e1d5d9f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d5eaa0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 1)\n",
      "Integrated case process. comm case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5ebc0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d5f400>, <__main__.Case object at 0x7973e1d5f5b0>, <__main__.Case object at 0x7973e1d5efb0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 59, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 59 loop--------------------\n",
      "----- starting point of Episode 60 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 60 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 60 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 60 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 60 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 60 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 60 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 60 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5f160>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5f4c0>, <__main__.Case object at 0x7973e1d5e890>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5f0d0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5ed40>, <__main__.Case object at 0x7973e1d5e8c0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d5ebc0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5f220>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "Episode: 60, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 60 loop--------------------\n",
      "----- starting point of Episode 61 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 61 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 61 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 61 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 61 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 61 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 61 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 61 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5f160>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d5fac0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d5fb80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d5ebc0>, <__main__.Case object at 0x7973e1d5eec0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 61, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 61 loop--------------------\n",
      "----- starting point of Episode 62 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 62 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 62 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 62 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 62 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 62 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 62 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 62 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5e530>, <__main__.Case object at 0x7973e1d5e8f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d5efb0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 1)\n",
      "Integrated case process. comm case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d5ebc0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5c520>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5f580>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 62, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 62 loop--------------------\n",
      "----- starting point of Episode 63 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 63 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 63 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 63 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 63 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 63 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 63 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 63 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d5d630>, <__main__.Case object at 0x7973e1d5f160>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5fdf0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d5eb30>, <__main__.Case object at 0x7973e1d5ead0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5f6d0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5ebc0>, <__main__.Case object at 0x7973e1d5c070>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "Episode: 63, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 63 loop--------------------\n",
      "----- starting point of Episode 64 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 64 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 64 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 64 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 64 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 64 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 64 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 64 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d5f2b0>, <__main__.Case object at 0x7973e1d5d630>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d5f370>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5f460>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5fdc0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 64, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 64 loop--------------------\n",
      "----- starting point of Episode 65 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 65 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 65 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 65 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 65 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 65 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 65 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 65 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d5ebc0>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5db10>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5f580>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 1)\n",
      "Integrated case process. comm case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5eaa0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 65, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 65 loop--------------------\n",
      "----- starting point of Episode 66 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 66 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 66 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 66 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 66 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 66 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 66 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 66 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5d630>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5f940>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d5f520>, <__main__.Case object at 0x7973e1d5f0d0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.6, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.6, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.6, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5ebc0>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5fd30>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5d9f0>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5c6a0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "Episode: 66, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 66 loop--------------------\n",
      "----- starting point of Episode 67 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 67 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 67 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 67 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 67 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 67 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 67 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 67 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d36fe0>, <__main__.Case object at 0x7973e1d5e980>, <__main__.Case object at 0x7973e1d5e890>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5d9f0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 0.19999999999999996, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 0.19999999999999996, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 0.19999999999999996, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 1, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d27ca0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d52710>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5f2b0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5eb30>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (2, 2) is empty. Temporary case base stored to the case base: ((2, 2), 4, 1)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 1)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "Episode: 67, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 67 loop--------------------\n",
      "----- starting point of Episode 68 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 68 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 68 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 68 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 68 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((2, 2), 4, 1, 29, None)\n",
      "----- starting point of Episode 68 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 68 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "----- starting point of Episode 68 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 1\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 1, 1, 32, None)\n",
      "comm next state for agent 1: ((3, 2), 2, 1, 38, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5fa00>, <__main__.Case object at 0x7973e1d5e8f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d25960>, <__main__.Case object at 0x7973e1d25b10>, <__main__.Case object at 0x7973e1d53700>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 1, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 1, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (2, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 2), 4, 0.5)\n",
      "Episode succeeded, case (1, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 2), 4, 0.5)\n",
      "Episode succeeded, case (0, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 1), 2, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 2, 0.5)\n",
      "Integrated case process. comm case (4, 2) is empty. Temporary case base stored to the case base: ((4, 2), 3, 1)\n",
      "Integrated case process. comm case (4, 1) is empty. Temporary case base stored to the case base: ((4, 1), 2, 1)\n",
      "Integrated case process. comm case (4, 0) is empty. Temporary case base stored to the case base: ((4, 0), 2, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5efb0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d5eb30>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5f9d0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 1, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 68, Total Steps: 8, Total Rewards: [43, 45], Status Episode: True\n",
      "------------------------------------------End of episode 68 loop--------------------\n",
      "----- starting point of Episode 69 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 1, 17, None)\n",
      "----- starting point of Episode 69 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 1, 18, None)\n",
      "----- starting point of Episode 69 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 1, 19, None)\n",
      "----- starting point of Episode 69 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 69 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "----- starting point of Episode 69 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 1, 23, None)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5c6a0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d02860>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.6, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.6, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5ec50>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d5c550>, <__main__.Case object at 0x7973e1d5e980>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (2, 2), solution: 4, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "Episode: 69, Total Steps: 6, Total Rewards: [-12, 45], Status Episode: False\n",
      "------------------------------------------End of episode 69 loop--------------------\n",
      "----- starting point of Episode 70 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 2, 0.6, 17, None)\n",
      "----- starting point of Episode 70 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((0, 1), 2, 0.6, 18, None)\n",
      "----- starting point of Episode 70 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((0, 2), 4, 0.6, 19, None)\n",
      "----- starting point of Episode 70 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 23, None)\n",
      "----- starting point of Episode 70 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 23, None)\n",
      "----- starting point of Episode 70 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((1, 2), 4, 0.6, 23, None)\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d273d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d3c820>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 23\n",
      "case content after REVISE for agent 0, problem: (0, 2), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (0, 1), solution: 2, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d5e980>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d278e0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (1, 2) is empty. Temporary case base stored to the case base: ((1, 2), 4, 0.6)\n",
      "Integrated case process. comm case (0, 2) is empty. Temporary case base stored to the case base: ((0, 2), 4, 0.6)\n",
      "Integrated case process. comm case (0, 1) is empty. Temporary case base stored to the case base: ((0, 1), 2, 0.6)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 2, 0.6)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (1, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 1), solution: 2, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 2, tv: 0.6\n",
      "Episode: 70, Total Steps: 6, Total Rewards: [-12, 45], Status Episode: False\n",
      "------------------------------------------End of episode 70 loop--------------------\n",
      "----- starting point of Episode 71 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 71 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 71 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 71 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 71 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 71 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 71 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 1\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from problem solver: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "----- starting point of Episode 71 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from problem solver: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: 0\n",
      "action type of agent: 0: problem solver, agent learned\n",
      "comm next state for agent 1: 0\n",
      "action type of agent: 1: problem solver, agent learned\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5ebc0>, <__main__.Case object at 0x7973e1d03ca0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d03160>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d3fe80>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5e9b0>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5f8b0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (1, 2), solution: 4, tv: 0.19999999999999996, time steps: 23\n",
      "case content after REVISE for agent 1, problem: (0, 2), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (0, 1), solution: 2, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 2, tv: 0.19999999999999996, time steps: 17\n",
      "Episode succeeded, case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 4, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 1, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5\n",
      "Episode: 71, Total Steps: 13, Total Rewards: [-22, 45], Status Episode: False\n",
      "------------------------------------------End of episode 71 loop--------------------\n",
      "----- starting point of Episode 72 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 72 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5f910>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5c550>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5ff70>, <__main__.Case object at 0x7973e1d5db10>, <__main__.Case object at 0x7973e1d5eaa0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5ef80>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5f4f0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.6, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "Episode: 72, Total Steps: 15, Total Rewards: [-24, 45], Status Episode: False\n",
      "------------------------------------------End of episode 72 loop--------------------\n",
      "----- starting point of Episode 73 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 73 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 73 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 73 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 73 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 73 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 73 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 73 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 73 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d5f0d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d3fe80>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d269b0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d5f940>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.7, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.7\n",
      "Episode: 73, Total Steps: 9, Total Rewards: [-18, 45], Status Episode: False\n",
      "------------------------------------------End of episode 73 loop--------------------\n",
      "----- starting point of Episode 74 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 74 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d3fe80>, <__main__.Case object at 0x7973e1d3ebf0>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d5cfa0>, <__main__.Case object at 0x7973e1d5fdf0>, <__main__.Case object at 0x7973e1d5ec20>, <__main__.Case object at 0x7973e1d5f010>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5f2b0>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5fb20>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d5f400>, <__main__.Case object at 0x7973e1d5ee30>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d5ed70>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5ef80>, <__main__.Case object at 0x7973e1d5f910>, <__main__.Case object at 0x7973e1d5eb30>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d5e530>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5f610>, <__main__.Case object at 0x7973e1d5e920>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5ff70>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.7999999999999999, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.7999999999999999\n",
      "Episode: 74, Total Steps: 18, Total Rewards: [-27, 45], Status Episode: False\n",
      "------------------------------------------End of episode 74 loop--------------------\n",
      "----- starting point of Episode 75 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 75 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5cbe0>, <__main__.Case object at 0x7973e1d5fe20>, <__main__.Case object at 0x7973e1d5fdf0>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5e980>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5df30>, <__main__.Case object at 0x7973e1d5f040>, <__main__.Case object at 0x7973e1d5f250>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5dae0>, <__main__.Case object at 0x7973e1d5f0a0>, <__main__.Case object at 0x7973e1d5ea70>, <__main__.Case object at 0x7973e1d5ff10>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d74160>, <__main__.Case object at 0x7973e1d74280>, <__main__.Case object at 0x7973e1d743a0>, <__main__.Case object at 0x7973e1d744f0>, <__main__.Case object at 0x7973e1d745e0>, <__main__.Case object at 0x7973e1d74700>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d3ff70>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d5edd0>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5e9e0>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5e920>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5fee0>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d5e8c0>, <__main__.Case object at 0x7973e1d5ebf0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5e590>, <__main__.Case object at 0x7973e1d5fbb0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d5f4f0>, <__main__.Case object at 0x7973e1d740d0>, <__main__.Case object at 0x7973e1d741f0>, <__main__.Case object at 0x7973e1d5f010>, <__main__.Case object at 0x7973e1d74310>, <__main__.Case object at 0x7973e1d74550>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d5fb80>, <__main__.Case object at 0x7973e1d5ed70>, <__main__.Case object at 0x7973e1d5f910>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5cfa0>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5e530>, <__main__.Case object at 0x7973e1d5f610>, <__main__.Case object at 0x7973e1d5f5b0>, <__main__.Case object at 0x7973e1d5ea40>, <__main__.Case object at 0x7973e1d5f700>, <__main__.Case object at 0x7973e1d5f280>, <__main__.Case object at 0x7973e1d5c640>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5fa90>, <__main__.Case object at 0x7973e1d5fa30>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5db10>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d74190>, <__main__.Case object at 0x7973e1d742b0>, <__main__.Case object at 0x7973e1d743d0>, <__main__.Case object at 0x7973e1d74340>, <__main__.Case object at 0x7973e1d74610>, <__main__.Case object at 0x7973e1d74730>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.8999999999999999, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.8999999999999999\n",
      "Episode: 75, Total Steps: 35, Total Rewards: [-44, 45], Status Episode: False\n",
      "------------------------------------------End of episode 75 loop--------------------\n",
      "----- starting point of Episode 76 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 76 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 76 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 76 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 76 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 76 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is locked. Done status: True, win status: False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d3ff70>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d34be0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d3e5f0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.4999999999999999, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.4999999999999999\n",
      "Episode: 76, Total Steps: 6, Total Rewards: [-14, 45], Status Episode: False\n",
      "------------------------------------------End of episode 76 loop--------------------\n",
      "----- starting point of Episode 77 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 77 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 77 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 77 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 77 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 77 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 77 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.4999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 77 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.4999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 77 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.4999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d3fe80>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5f0d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d25ed0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d5fbb0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.5999999999999999, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.5999999999999999\n",
      "Episode: 77, Total Steps: 9, Total Rewards: [-18, 45], Status Episode: False\n",
      "------------------------------------------End of episode 77 loop--------------------\n",
      "----- starting point of Episode 78 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 78 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.5999999999999999, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d017b0>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3ffa0>, <__main__.Case object at 0x7973e1d3d330>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d5f010>, <__main__.Case object at 0x7973e1d5df30>, <__main__.Case object at 0x7973e1d5e980>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5edd0>, <__main__.Case object at 0x7973e1d5e9e0>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5fc70>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d5e080>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5ed70>, <__main__.Case object at 0x7973e1d5cfa0>, <__main__.Case object at 0x7973e1d5f610>, <__main__.Case object at 0x7973e1d5f700>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3ce20>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d3f0a0>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5ec50>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5fbe0>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d5f0a0>, <__main__.Case object at 0x7973e1d5f4c0>, <__main__.Case object at 0x7973e1d5f970>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3c820>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d5fcd0>, <__main__.Case object at 0x7973e1d5f2b0>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5ebc0>, <__main__.Case object at 0x7973e1d5ed10>, <__main__.Case object at 0x7973e1d5e920>, <__main__.Case object at 0x7973e1d5faf0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5cbe0>, <__main__.Case object at 0x7973e1d5dae0>, <__main__.Case object at 0x7973e1d5ff10>, <__main__.Case object at 0x7973e1d5ff40>, <__main__.Case object at 0x7973e1d5f220>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5fb50>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.6999999999999998, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6999999999999998\n",
      "Episode: 78, Total Steps: 24, Total Rewards: [-33, 45], Status Episode: False\n",
      "------------------------------------------End of episode 78 loop--------------------\n",
      "----- starting point of Episode 79 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 26 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 27 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 28 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 29 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 30 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 31 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 32 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 33 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 34 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 35 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 36 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 37 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 38 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 39 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 40 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 41 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 42 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 43 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 44 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 45 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 46 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 47 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 48 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 49 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 50 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 51 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 52 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 53 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 54 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 55 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 56 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 57 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 58 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 59 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 60 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 61 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 62 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 63 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 64 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 65 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 66 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 67 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 79 in steps 68 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 hit the obstacle!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.6999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: False\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51480>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d5f280>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5f400>, <__main__.Case object at 0x7973e1d5f4f0>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d5f700>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5ef80>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5efb0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3c2e0>, <__main__.Case object at 0x7973e1d3fac0>, <__main__.Case object at 0x7973e1d745e0>, <__main__.Case object at 0x7973e1d74070>, <__main__.Case object at 0x7973e1d740d0>, <__main__.Case object at 0x7973e1d74730>, <__main__.Case object at 0x7973e1d742e0>, <__main__.Case object at 0x7973e1d74640>, <__main__.Case object at 0x7973e1d750f0>, <__main__.Case object at 0x7973e1d74fa0>, <__main__.Case object at 0x7973e1d74eb0>, <__main__.Case object at 0x7973e1d74d60>, <__main__.Case object at 0x7973e1d74c40>, <__main__.Case object at 0x7973e1d74af0>, <__main__.Case object at 0x7973e1d74a00>, <__main__.Case object at 0x7973e1d74910>, <__main__.Case object at 0x7973e1d747f0>, <__main__.Case object at 0x7973e1d75270>, <__main__.Case object at 0x7973e1d75360>, <__main__.Case object at 0x7973e1d75480>, <__main__.Case object at 0x7973e1d755a0>, <__main__.Case object at 0x7973e1d756f0>, <__main__.Case object at 0x7973e1d757e0>, <__main__.Case object at 0x7973e1d75900>, <__main__.Case object at 0x7973e1d75a20>, <__main__.Case object at 0x7973e1d75b70>, <__main__.Case object at 0x7973e1d75c60>, <__main__.Case object at 0x7973e1d75d80>, <__main__.Case object at 0x7973e1d75ea0>, <__main__.Case object at 0x7973e1d75ff0>, <__main__.Case object at 0x7973e1d760e0>, <__main__.Case object at 0x7973e1d76200>, <__main__.Case object at 0x7973e1d76320>, <__main__.Case object at 0x7973e1d76470>, <__main__.Case object at 0x7973e1d76560>, <__main__.Case object at 0x7973e1d76680>, <__main__.Case object at 0x7973e1d767a0>, <__main__.Case object at 0x7973e1d768f0>, <__main__.Case object at 0x7973e1d769e0>, <__main__.Case object at 0x7973e1d76b00>, <__main__.Case object at 0x7973e1d76c20>, <__main__.Case object at 0x7973e1d76d70>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5eb30>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5f4c0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5fd30>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5ff70>, <__main__.Case object at 0x7973e1d5f370>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5cbe0>, <__main__.Case object at 0x7973e1d5ff40>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5c550>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d3e5f0>, <__main__.Case object at 0x7973e1d74190>, <__main__.Case object at 0x7973e1d74280>, <__main__.Case object at 0x7973e1d5f160>, <__main__.Case object at 0x7973e1d74370>, <__main__.Case object at 0x7973e1d740a0>, <__main__.Case object at 0x7973e1d74340>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d751e0>, <__main__.Case object at 0x7973e1d74f10>, <__main__.Case object at 0x7973e1d74e20>, <__main__.Case object at 0x7973e1d5e9b0>, <__main__.Case object at 0x7973e1d74cd0>, <__main__.Case object at 0x7973e1d74a90>, <__main__.Case object at 0x7973e1d74970>, <__main__.Case object at 0x7973e1d5fa90>, <__main__.Case object at 0x7973e1d74850>, <__main__.Case object at 0x7973e1d752d0>, <__main__.Case object at 0x7973e1d753f0>, <__main__.Case object at 0x7973e1d3e1d0>, <__main__.Case object at 0x7973e1d75510>, <__main__.Case object at 0x7973e1d75750>, <__main__.Case object at 0x7973e1d75870>, <__main__.Case object at 0x7973e1d75ab0>, <__main__.Case object at 0x7973e1d75990>, <__main__.Case object at 0x7973e1d75bd0>, <__main__.Case object at 0x7973e1d75cf0>, <__main__.Case object at 0x7973e1d75f30>, <__main__.Case object at 0x7973e1d75e10>, <__main__.Case object at 0x7973e1d76050>, <__main__.Case object at 0x7973e1d76170>, <__main__.Case object at 0x7973e1d763b0>, <__main__.Case object at 0x7973e1d76290>, <__main__.Case object at 0x7973e1d764d0>, <__main__.Case object at 0x7973e1d765f0>, <__main__.Case object at 0x7973e1d76830>, <__main__.Case object at 0x7973e1d76710>, <__main__.Case object at 0x7973e1d76950>, <__main__.Case object at 0x7973e1d76a70>, <__main__.Case object at 0x7973e1d76cb0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 1, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.6, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode not succeeded, temporary case base from own experience is not stored to the case base\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 1, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5c070>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5fd00>, <__main__.Case object at 0x7973e1d5f0a0>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5d0c0>, <__main__.Case object at 0x7973e1d5c6a0>, <__main__.Case object at 0x7973e1d5e530>, <__main__.Case object at 0x7973e1d5f2b0>, <__main__.Case object at 0x7973e1d5ed10>, <__main__.Case object at 0x7973e1d5fdf0>, <__main__.Case object at 0x7973e1d5ff10>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5fc40>, <__main__.Case object at 0x7973e1d5f670>, <__main__.Case object at 0x7973e1d5fa30>, <__main__.Case object at 0x7973e1d3e0b0>, <__main__.Case object at 0x7973e1d3c400>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d74220>, <__main__.Case object at 0x7973e1d74040>, <__main__.Case object at 0x7973e1d741f0>, <__main__.Case object at 0x7973e1d74310>, <__main__.Case object at 0x7973e1d743d0>, <__main__.Case object at 0x7973e1d750c0>, <__main__.Case object at 0x7973e1d75180>, <__main__.Case object at 0x7973e1d75120>, <__main__.Case object at 0x7973e1d74df0>, <__main__.Case object at 0x7973e1d74d30>, <__main__.Case object at 0x7973e1d74c10>, <__main__.Case object at 0x7973e1d74ca0>, <__main__.Case object at 0x7973e1d749a0>, <__main__.Case object at 0x7973e1d748b0>, <__main__.Case object at 0x7973e1d746a0>, <__main__.Case object at 0x7973e1d74820>, <__main__.Case object at 0x7973e1d75390>, <__main__.Case object at 0x7973e1d754b0>, <__main__.Case object at 0x7973e1d755d0>, <__main__.Case object at 0x7973e1d75540>, <__main__.Case object at 0x7973e1d75810>, <__main__.Case object at 0x7973e1d75930>, <__main__.Case object at 0x7973e1d75a50>, <__main__.Case object at 0x7973e1d759c0>, <__main__.Case object at 0x7973e1d75c90>, <__main__.Case object at 0x7973e1d75db0>, <__main__.Case object at 0x7973e1d75ed0>, <__main__.Case object at 0x7973e1d75e40>, <__main__.Case object at 0x7973e1d76110>, <__main__.Case object at 0x7973e1d76230>, <__main__.Case object at 0x7973e1d76350>, <__main__.Case object at 0x7973e1d762c0>, <__main__.Case object at 0x7973e1d76590>, <__main__.Case object at 0x7973e1d766b0>, <__main__.Case object at 0x7973e1d767d0>, <__main__.Case object at 0x7973e1d76740>, <__main__.Case object at 0x7973e1d76a10>, <__main__.Case object at 0x7973e1d76b30>, <__main__.Case object at 0x7973e1d76c50>, <__main__.Case object at 0x7973e1d76bc0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.7999999999999998, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.7999999999999998\n",
      "Episode: 79, Total Steps: 69, Total Rewards: [-78, 45], Status Episode: False\n",
      "------------------------------------------End of episode 79 loop--------------------\n",
      "----- starting point of Episode 80 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 10 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 11 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 12 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 13 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 14 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 15 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 16 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 1\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 17 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 0\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 18 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 19 loop -----\n",
      "Physical Action for Agent 0 from problem solver: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 20 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 21 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 22 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 23 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 24 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "----- starting point of Episode 80 in steps 25 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.7999999999999998, 12, None)\n",
      "comm next state for agent 1: 0\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d50e80>, <__main__.Case object at 0x7973e1d02c20>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d5eb30>, <__main__.Case object at 0x7973e1d5eb90>, <__main__.Case object at 0x7973e1d5ed70>, <__main__.Case object at 0x7973e1d5ee30>, <__main__.Case object at 0x7973e1d5db10>, <__main__.Case object at 0x7973e1d5f160>, <__main__.Case object at 0x7973e1d5fb20>, <__main__.Case object at 0x7973e1d5f280>, <__main__.Case object at 0x7973e1d5e980>, <__main__.Case object at 0x7973e1d5f250>, <__main__.Case object at 0x7973e1d5fee0>, <__main__.Case object at 0x7973e1d5f040>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5ec20>, <__main__.Case object at 0x7973e1d5fc70>, <__main__.Case object at 0x7973e1d5f2b0>, <__main__.Case object at 0x7973e1d5ebf0>, <__main__.Case object at 0x7973e1d5fd60>, <__main__.Case object at 0x7973e1d3d2d0>, <__main__.Case object at 0x7973e1d3e1a0>, <__main__.Case object at 0x7973e1d3ebf0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5f4c0>, <__main__.Case object at 0x7973e1d5fcd0>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d5cbe0>, <__main__.Case object at 0x7973e1d5c640>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5fa90>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d5e590>, <__main__.Case object at 0x7973e1d5ef80>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5fd00>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5ed10>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5f5b0>, <__main__.Case object at 0x7973e1d37520>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.6, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 1, tv: 0.19999999999999996, time steps: 32\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 0, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 1, 0.5)\n",
      "Episode succeeded, case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (2, 2), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5fd30>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5ea40>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5f4f0>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5ef20>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5d0c0>, <__main__.Case object at 0x7973e1d5edd0>, <__main__.Case object at 0x7973e1d5ff10>, <__main__.Case object at 0x7973e1d5f670>, <__main__.Case object at 0x7973e1d3dcf0>, <__main__.Case object at 0x7973e1d3efb0>, <__main__.Case object at 0x7973e1d3fac0>]\n",
      "agent1 comm temp case base: []\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.8999999999999998, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.8999999999999998\n",
      "Episode: 80, Total Steps: 26, Total Rewards: [25, 45], Status Episode: True\n",
      "------------------------------------------End of episode 80 loop--------------------\n",
      "----- starting point of Episode 81 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.5, 0, None)\n",
      "----- starting point of Episode 81 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.5, 1, None)\n",
      "----- starting point of Episode 81 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.5, 18, None)\n",
      "----- starting point of Episode 81 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 0.5, 19, None)\n",
      "----- starting point of Episode 81 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 81 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 81 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999998, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 81 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999998, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 81 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999998, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 81 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.8999999999999998, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d5f4c0>, <__main__.Case object at 0x7973e1d5fb50>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5e530>, <__main__.Case object at 0x7973e1d5fa30>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d5fa90>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5fdf0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (2, 2), solution: 4, tv: 0.19999999999999996, time steps: 29\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 0.8999999999999998)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.8999999999999998\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d5faf0>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5f190>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5e590>, <__main__.Case object at 0x7973e1d5f700>, <__main__.Case object at 0x7973e1d5ee00>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 0.9999999999999998, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 4, 0.5)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.5)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.5)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.9999999999999998\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.5\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.5\n",
      "Episode: 81, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 81 loop--------------------\n",
      "----- starting point of Episode 82 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.6, 0, None)\n",
      "----- starting point of Episode 82 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.6, 1, None)\n",
      "----- starting point of Episode 82 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.6, 18, None)\n",
      "----- starting point of Episode 82 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 0.6, 19, None)\n",
      "----- starting point of Episode 82 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 82 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 82 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999998, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 82 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999998, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 82 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999998, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 82 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 0.9999999999999998, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d5fa90>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5ff40>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5eda0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5ef80>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d5e890>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.7, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.4999999999999998, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.4999999999999998\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5f700>, <__main__.Case object at 0x7973e1d5e530>, <__main__.Case object at 0x7973e1d5eaa0>, <__main__.Case object at 0x7973e1d5eec0>, <__main__.Case object at 0x7973e1d5f4f0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5ef20>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.09999999999999998, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.09999999999999998, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.09999999999999998, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.09999999999999998, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 82, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 82 loop--------------------\n",
      "----- starting point of Episode 83 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7, 0, None)\n",
      "----- starting point of Episode 83 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.7, 1, None)\n",
      "----- starting point of Episode 83 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.7, 18, None)\n",
      "----- starting point of Episode 83 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 0.7, 19, None)\n",
      "----- starting point of Episode 83 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 83 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 83 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 83 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 83 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 83 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d5f0a0>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5ef50>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d5ef80>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d5fb50>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.7999999999999999, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.7999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.7999999999999999, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.7999999999999999, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.09999999999999976, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7999999999999999\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d5cbe0>, <__main__.Case object at 0x7973e1d5f190>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5ff40>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5fd00>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5eda0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 4, 0.7)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.7)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.7)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.7)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.7\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.7\n",
      "Episode: 83, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 83 loop--------------------\n",
      "----- starting point of Episode 84 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.7999999999999999, 0, None)\n",
      "----- starting point of Episode 84 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.7999999999999999, 1, None)\n",
      "----- starting point of Episode 84 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.7999999999999999, 18, None)\n",
      "----- starting point of Episode 84 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 0.7999999999999999, 19, None)\n",
      "----- starting point of Episode 84 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 84 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 84 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 84 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 84 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 84 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d5f610>, <__main__.Case object at 0x7973e1d5ed10>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5c640>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5f940>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5fcd0>, <__main__.Case object at 0x7973e1d5fd00>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d5f580>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.8999999999999999, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.8999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.8999999999999999, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.8999999999999999, time steps: 0\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5ef20>, <__main__.Case object at 0x7973e1d5cbe0>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5f550>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5fb50>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5f4f0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5dae0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.29999999999999993, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.29999999999999993, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.29999999999999993, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.29999999999999993, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 84, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 84 loop--------------------\n",
      "----- starting point of Episode 85 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.8999999999999999, 0, None)\n",
      "----- starting point of Episode 85 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.8999999999999999, 1, None)\n",
      "----- starting point of Episode 85 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.8999999999999999, 18, None)\n",
      "----- starting point of Episode 85 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 0.8999999999999999, 19, None)\n",
      "----- starting point of Episode 85 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 85 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 85 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 85 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 85 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 85 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5fca0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5fd00>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d5ff40>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 0.9999999999999999, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 0.9999999999999999, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 0.9999999999999999, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 0.9999999999999999, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.9999999999999999\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5fb50>, <__main__.Case object at 0x7973e1d5f610>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5e590>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5ef80>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d5f4f0>, <__main__.Case object at 0x7973e1d5f4c0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 0.8999999999999999)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 0.8999999999999999)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.8999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.8999999999999999\n",
      "Episode: 85, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 85 loop--------------------\n",
      "----- starting point of Episode 86 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 0.9999999999999999, 0, None)\n",
      "----- starting point of Episode 86 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 0.9999999999999999, 1, None)\n",
      "----- starting point of Episode 86 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 0.9999999999999999, 18, None)\n",
      "----- starting point of Episode 86 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 0.9999999999999999, 19, None)\n",
      "----- starting point of Episode 86 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 86 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 86 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 86 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 86 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 86 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5fd00>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5fcd0>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5ffd0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d5c520>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5fc10>, <__main__.Case object at 0x7973e1d5dae0>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5fd30>, <__main__.Case object at 0x7973e1d5fd60>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5e590>, <__main__.Case object at 0x7973e1d5ff40>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5c640>, <__main__.Case object at 0x7973e1d5ea70>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.4999999999999999, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.4999999999999999, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.4999999999999999, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.4999999999999999, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.4999999999999999\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.4999999999999999\n",
      "Episode: 86, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 86 loop--------------------\n",
      "----- starting point of Episode 87 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 87 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 87 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 87 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 87 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 87 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 87 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 87 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 87 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 87 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5fcd0>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5f9d0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d5fe20>, <__main__.Case object at 0x7973e1d5f0a0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d5fc10>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5f6a0>, <__main__.Case object at 0x7973e1d5e590>, <__main__.Case object at 0x7973e1d5c640>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5f970>, <__main__.Case object at 0x7973e1d5eda0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5f070>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5ef50>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.09999999999999987, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.09999999999999987, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.09999999999999987, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.09999999999999987, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 87, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 87 loop--------------------\n",
      "----- starting point of Episode 88 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 88 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 88 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 88 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 88 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 88 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 88 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 88 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 88 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 88 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d5f610>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5e920>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5ee00>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d5f4f0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d5f9d0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d5fe20>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5faf0>, <__main__.Case object at 0x7973e1d5c640>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d5edd0>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5fa90>, <__main__.Case object at 0x7973e1d5f6a0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 88, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 88 loop--------------------\n",
      "----- starting point of Episode 89 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 89 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 89 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 89 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 89 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 89 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 89 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 89 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 89 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 89 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d5f4f0>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5ed10>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5f3a0>, <__main__.Case object at 0x7973e1d5ef20>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5e920>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5ece0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5ef80>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5fe20>, <__main__.Case object at 0x7973e1d5e9b0>, <__main__.Case object at 0x7973e1d5feb0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d5dae0>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5fa00>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 89, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 89 loop--------------------\n",
      "----- starting point of Episode 90 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 90 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 90 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 90 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 90 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 90 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 90 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 90 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 90 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 90 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d4ab60>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d5e080>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d5ed10>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5fe20>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d5c640>, <__main__.Case object at 0x7973e1d5f0a0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d5ef80>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d5edd0>, <__main__.Case object at 0x7973e1d5dae0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5fcd0>, <__main__.Case object at 0x7973e1d5ebf0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d5e920>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5ff40>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5e890>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 90, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 90 loop--------------------\n",
      "----- starting point of Episode 91 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 91 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 91 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 91 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 91 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 91 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 91 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 91 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 91 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 91 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5fd60>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5f610>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d5fa90>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5fe20>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d5c640>, <__main__.Case object at 0x7973e1d5ece0>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d5ea40>, <__main__.Case object at 0x7973e1d5e920>, <__main__.Case object at 0x7973e1d5e080>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5edd0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 91, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 91 loop--------------------\n",
      "----- starting point of Episode 92 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 92 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 92 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 92 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 92 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 92 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 92 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 92 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 92 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 92 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d5fa90>, <__main__.Case object at 0x7973e1d5ef20>, <__main__.Case object at 0x7973e1d5f700>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d5faf0>, <__main__.Case object at 0x7973e1d5fd00>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5e080>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d5f490>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5ead0>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5c640>, <__main__.Case object at 0x7973e1d5f520>, <__main__.Case object at 0x7973e1d5f580>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5fe20>, <__main__.Case object at 0x7973e1d5fd60>, <__main__.Case object at 0x7973e1d5ebf0>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5ff10>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 92, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 92 loop--------------------\n",
      "----- starting point of Episode 93 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 93 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 93 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 93 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 93 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 93 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 93 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 93 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 93 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 93 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d36590>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5e080>, <__main__.Case object at 0x7973e1d5ebf0>, <__main__.Case object at 0x7973e1d5f700>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5c640>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5f0a0>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5ead0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d51d50>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d5ea40>, <__main__.Case object at 0x7973e1d5ef50>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d5ed10>, <__main__.Case object at 0x7973e1d5fe50>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5f9d0>, <__main__.Case object at 0x7973e1d5ef20>, <__main__.Case object at 0x7973e1d5cfa0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 93, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 93 loop--------------------\n",
      "----- starting point of Episode 94 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 94 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 94 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 94 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 94 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 94 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 94 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 94 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 94 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 94 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d5e8f0>, <__main__.Case object at 0x7973e1d5feb0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5fd60>, <__main__.Case object at 0x7973e1d5f7f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d5c640>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5f490>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5f460>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d4b070>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d5fb50>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d5ea40>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 94, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 94 loop--------------------\n",
      "----- starting point of Episode 95 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 95 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 95 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 95 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 95 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 95 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 95 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 95 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 95 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 95 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d278e0>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d5e890>, <__main__.Case object at 0x7973e1d5fd00>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5ebf0>, <__main__.Case object at 0x7973e1d5ec80>, <__main__.Case object at 0x7973e1d5f4f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5ef20>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d5f0d0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d4bf70>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5e920>, <__main__.Case object at 0x7973e1d5cfa0>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5cbe0>, <__main__.Case object at 0x7973e1d5fc10>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d492d0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5c640>, <__main__.Case object at 0x7973e1d5feb0>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5c6a0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 95, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 95 loop--------------------\n",
      "----- starting point of Episode 96 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 96 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 96 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 96 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 96 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 96 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 96 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 96 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 96 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 96 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d25ed0>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d4ac50>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d5fd30>, <__main__.Case object at 0x7973e1d5f2e0>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5f0a0>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d5e920>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d5fb50>, <__main__.Case object at 0x7973e1d5f460>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5ebf0>, <__main__.Case object at 0x7973e1d5f700>, <__main__.Case object at 0x7973e1d5e590>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d5f610>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5fd60>, <__main__.Case object at 0x7973e1d5fe20>, <__main__.Case object at 0x7973e1d5fd00>, <__main__.Case object at 0x7973e1d5ea70>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 96, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 96 loop--------------------\n",
      "----- starting point of Episode 97 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 97 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 97 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 97 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 97 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 97 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 97 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 97 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 97 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 97 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d52350>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d37ee0>, <__main__.Case object at 0x7973e1d5ffd0>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5e080>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5e8f0>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d5fd60>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d5ffa0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.6, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 0.6\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d48eb0>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5f0d0>, <__main__.Case object at 0x7973e1d5ef20>, <__main__.Case object at 0x7973e1d5eda0>, <__main__.Case object at 0x7973e1d5e770>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d50a60>, <__main__.Case object at 0x7973e1d269b0>, <__main__.Case object at 0x7973e1d4b670>, <__main__.Case object at 0x7973e1d498d0>, <__main__.Case object at 0x7973e1d341f0>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5fac0>, <__main__.Case object at 0x7973e1d5fd30>, <__main__.Case object at 0x7973e1d5ee00>, <__main__.Case object at 0x7973e1d5fb50>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Integrated case process. comm case (3, 0) is empty. Temporary case base stored to the case base: ((3, 0), 4, 1)\n",
      "Integrated case process. comm case (2, 0) is empty. Temporary case base stored to the case base: ((2, 0), 4, 1)\n",
      "Integrated case process. comm case (1, 0) is empty. Temporary case base stored to the case base: ((1, 0), 4, 1)\n",
      "Integrated case process. comm case (0, 0) is empty. Temporary case base stored to the case base: ((0, 0), 4, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "Episode: 97, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 97 loop--------------------\n",
      "----- starting point of Episode 98 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 98 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 98 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 98 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 98 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 98 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 98 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 98 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 98 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 98 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d273d0>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d5cfa0>, <__main__.Case object at 0x7973e1d5f4f0>, <__main__.Case object at 0x7973e1d5fc40>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5f550>, <__main__.Case object at 0x7973e1d5fa90>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d51840>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d4bb20>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d5fd00>, <__main__.Case object at 0x7973e1d5fd30>, <__main__.Case object at 0x7973e1d5e080>, <__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d5f070>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "case content after REVISE for agent 0, problem: (4, 4), solution: 0, tv: 0.19999999999999996, time steps: 12\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d4a7a0>, <__main__.Case object at 0x7973e1d35690>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5fd60>, <__main__.Case object at 0x7973e1d5f1f0>, <__main__.Case object at 0x7973e1d5ea70>, <__main__.Case object at 0x7973e1d5f100>, <__main__.Case object at 0x7973e1d5f940>, <__main__.Case object at 0x7973e1d5ef80>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d52800>, <__main__.Case object at 0x7973e1d03ca0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d369e0>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5ffa0>, <__main__.Case object at 0x7973e1d5f580>, <__main__.Case object at 0x7973e1d5e590>, <__main__.Case object at 0x7973e1d5feb0>, <__main__.Case object at 0x7973e1d5d0c0>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.6, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.6, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.6, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.6, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 0.6\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 0.6\n",
      "Episode: 98, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 98 loop--------------------\n",
      "----- starting point of Episode 99 in steps 0 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 0), 2, 1, 1, None)\n",
      "comm next state for agent 1: ((0, 0), 4, 1, 0, None)\n",
      "----- starting point of Episode 99 in steps 1 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 1), 2, 1, 4, None)\n",
      "comm next state for agent 1: ((1, 0), 4, 1, 1, None)\n",
      "----- starting point of Episode 99 in steps 2 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 3\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((4, 2), 3, 1, 6, None)\n",
      "comm next state for agent 1: ((2, 0), 4, 1, 18, None)\n",
      "----- starting point of Episode 99 in steps 3 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 2), 2, 1, 38, None)\n",
      "comm next state for agent 1: ((3, 0), 4, 1, 19, None)\n",
      "----- starting point of Episode 99 in steps 4 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 4\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is ongoing!\n",
      "win status agent 1 = False\n",
      "wins all agent situation in the environment: [False, False]\n",
      "comm next state for agent 0: ((3, 3), 4, 1, 39, None)\n",
      "comm next state for agent 1: ((4, 0), 2, 1, 1, None)\n",
      "----- starting point of Episode 99 in steps 5 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 2\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 reach the target!\n",
      "win status agent 1 = True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 3), 2, 1, 41, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 99 in steps 6 loop -----\n",
      "Physical Action for Agent 0 from case base: 3\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 99 in steps 7 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 99 in steps 8 loop -----\n",
      "Physical Action for Agent 0 from case base: 4\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 is ongoing!\n",
      "win status agent 0 = False\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [False, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "----- starting point of Episode 99 in steps 9 loop -----\n",
      "Physical Action for Agent 0 from case base: 2\n",
      "Physical Action for Agent 1 from case base: 0\n",
      "agent 0 reach the target!\n",
      "win status agent 0 = True\n",
      "agent 1 is locked. Done status: True, win status: True\n",
      "wins all agent situation in the environment: [True, True]\n",
      "comm next state for agent 0: ((4, 4), 0, 1, 12, None)\n",
      "comm next state for agent 1: ((4, 1), 2, 1, 4, None)\n",
      "win status of agent 0  before update the case base: True\n",
      "agent0 own temp case base: [<__main__.Case object at 0x7973e1d505b0>, <__main__.Case object at 0x7973e1d255a0>, <__main__.Case object at 0x7973e1d48a00>, <__main__.Case object at 0x7973e1d34be0>, <__main__.Case object at 0x7973e1d5e9b0>, <__main__.Case object at 0x7973e1d5fd30>, <__main__.Case object at 0x7973e1d5e590>, <__main__.Case object at 0x7973e1d5fc40>, <__main__.Case object at 0x7973e1d5fd60>, <__main__.Case object at 0x7973e1d5f100>]\n",
      "agent0 comm temp case base: [<__main__.Case object at 0x7973e1d03760>, <__main__.Case object at 0x7973e1d53760>, <__main__.Case object at 0x7973e1d24a60>, <__main__.Case object at 0x7973e1d48ee0>, <__main__.Case object at 0x7973e1d37520>, <__main__.Case object at 0x7973e1d02860>, <__main__.Case object at 0x7973e1d5fca0>, <__main__.Case object at 0x7973e1d5f0a0>, <__main__.Case object at 0x7973e1d03160>, <__main__.Case object at 0x7973e1d5f1f0>]\n",
      "case content after REVISE for agent 0, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 0, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 0, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 0, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 0, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 0, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (3, 0), solution: 4, tv: 1, time steps: 19\n",
      "case content after REVISE for agent 0, problem: (2, 0), solution: 4, tv: 1, time steps: 18\n",
      "case content after REVISE for agent 0, problem: (1, 0), solution: 4, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 0, problem: (0, 0), solution: 4, tv: 1, time steps: 0\n",
      "Episode succeeded, case (4, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "Episode succeeded, case (3, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((3, 0), 4, 0.5)\n",
      "Episode succeeded, case (2, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((2, 0), 4, 0.5)\n",
      "Episode succeeded, case (1, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((1, 0), 4, 0.5)\n",
      "Episode succeeded, case (0, 0) for agent 0 is not empty. Temporary case base that not stored to the case base: ((0, 0), 4, 0.5)\n",
      "Integrated case process. comm case (4, 4) is empty. Temporary case base stored to the case base: ((4, 4), 0, 1)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (2, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (1, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (0, 0), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "win status of agent 1  before update the case base: True\n",
      "agent1 own temp case base: [<__main__.Case object at 0x7973e1d536d0>, <__main__.Case object at 0x7973e1d48400>, <__main__.Case object at 0x7973e1d351e0>, <__main__.Case object at 0x7973e1d360b0>, <__main__.Case object at 0x7973e1d5c520>, <__main__.Case object at 0x7973e1d5e770>, <__main__.Case object at 0x7973e1d5feb0>, <__main__.Case object at 0x7973e1d5fe50>, <__main__.Case object at 0x7973e1d5f6d0>, <__main__.Case object at 0x7973e1d5dae0>]\n",
      "agent1 comm temp case base: [<__main__.Case object at 0x7973e1d53220>, <__main__.Case object at 0x7973e1d02d10>, <__main__.Case object at 0x7973e1d49c90>, <__main__.Case object at 0x7973e1d356f0>, <__main__.Case object at 0x7973e1d5f7f0>, <__main__.Case object at 0x7973e1d5e080>, <__main__.Case object at 0x7973e1d5fdc0>, <__main__.Case object at 0x7973e1d5c640>, <__main__.Case object at 0x7973e1d5f4f0>, <__main__.Case object at 0x7973e1d5fa00>]\n",
      "case content after REVISE for agent 1, problem: (4, 3), solution: 2, tv: 1, time steps: 41\n",
      "case content after REVISE for agent 1, problem: (3, 3), solution: 4, tv: 1, time steps: 39\n",
      "case content after REVISE for agent 1, problem: (3, 2), solution: 2, tv: 1, time steps: 38\n",
      "case content after REVISE for agent 1, problem: (4, 2), solution: 3, tv: 1, time steps: 6\n",
      "case content after REVISE for agent 1, problem: (4, 1), solution: 2, tv: 1, time steps: 4\n",
      "case content after REVISE for agent 1, problem: (4, 0), solution: 2, tv: 1, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (4, 4), solution: 0, tv: 1, time steps: 12\n",
      "case content after REVISE for agent 1, problem: (3, 0), solution: 4, tv: 0.19999999999999996, time steps: 19\n",
      "case content after REVISE for agent 1, problem: (2, 0), solution: 4, tv: 0.19999999999999996, time steps: 18\n",
      "case content after REVISE for agent 1, problem: (1, 0), solution: 4, tv: 0.19999999999999996, time steps: 1\n",
      "case content after REVISE for agent 1, problem: (0, 0), solution: 4, tv: 0.19999999999999996, time steps: 0\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 4) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 4), 0, 0.5)\n",
      "Episode succeeded, case (4, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 3), 2, 0.5)\n",
      "Episode succeeded, case (3, 3) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 3), 4, 0.5)\n",
      "Episode succeeded, case (3, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((3, 2), 2, 0.5)\n",
      "Episode succeeded, case (4, 2) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 2), 3, 0.5)\n",
      "Episode succeeded, case (4, 1) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 1), 2, 0.5)\n",
      "Episode succeeded, case (4, 0) for agent 1 is not empty. Temporary case base that not stored to the case base: ((4, 0), 2, 0.5)\n",
      "cases content after RETAIN, problem: (4, 3), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (3, 3), solution: 4, tv: 1\n",
      "cases content after RETAIN, problem: (3, 2), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 2), solution: 3, tv: 1\n",
      "cases content after RETAIN, problem: (4, 1), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 0), solution: 2, tv: 1\n",
      "cases content after RETAIN, problem: (4, 4), solution: 0, tv: 1\n",
      "Episode: 99, Total Steps: 10, Total Rewards: [41, 45], Status Episode: True\n",
      "------------------------------------------End of episode 99 loop--------------------\n",
      "Success rate: 75.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import json\n",
    "import psutil\n",
    "import pynvml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from environment_ma_reward_distance_dynamic_notrandom import Env\n",
    "\n",
    "\n",
    "def learn(self, agent_idx, state, action, reward, next_state, case_base=None):\n",
    "        state = tuple(state)\n",
    "        next_state = tuple(next_state)\n",
    "        current_q = self.q_tables[agent_idx][state][action]\n",
    "        max_next_q = max(self.q_tables[agent_idx][next_state])\n",
    "\n",
    "        # Calculate the Q-update with weighted distance-based pull reward if case_base exists\n",
    "        if case_base:\n",
    "            print(f\"Calculating weighted distance-based pull reward for agent {agent_idx}\")\n",
    "            pull_reward = 0  # Initialize pull reward\n",
    "            \n",
    "            for case in case_base:\n",
    "                problems = case.problem if isinstance(case.problem, list) else [case.problem]\n",
    "                \n",
    "                weight = case.trust_value\n",
    "                \n",
    "                # Calculate the pull reward based on the weighted difference in distances\n",
    "                for p in problems:\n",
    "                    distance_current = np.linalg.norm(np.array(state) - np.array(p))\n",
    "                    distance_next = np.linalg.norm(np.array(next_state) - np.array(p))\n",
    "\n",
    "                    distance_diff = distance_current - distance_next\n",
    "                    distance_diff = weight * distance_diff\n",
    "                    pull_reward += np.log1p(abs(distance_diff)) * np.sign(distance_diff)\n",
    "                    pull_reward = np.clip(pull_reward, -1 * self.epsilon, self.epsilon)\n",
    "                    # pull_reward = np.clip(pull_reward, -0.1, 0.1) \n",
    "            \n",
    "            print(f\"Calculating pull reward agent {agent_idx}: from state {state} with action {action} to next state {next_state}: pull reward: {pull_reward}\")\n",
    "            new_q = current_q + self.learning_rate * (reward + pull_reward + self.discount_factor * max_next_q - current_q)\n",
    "        else:\n",
    "            # Standard Q-learning update without pull reward\n",
    "            print(f\"No communication. Standard Q-learning update for agent {agent_idx}\")\n",
    "            new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_next_q - current_q)\n",
    "\n",
    "        self.q_tables[agent_idx][state][action] = new_q\n",
    "\n",
    "class ProblemSolver:\n",
    "    def __init__(self, num_actions, env, alpha, gamma, epsilon):\n",
    "        self.env = env\n",
    "        self.num_actions = num_actions\n",
    "        self.learning_rate = alpha\n",
    "        self.discount_factor = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_tables = [defaultdict(lambda: [0.0] * num_actions) for _ in range(env.num_agents)]\n",
    "\n",
    "    @staticmethod\n",
    "    def arg_max(state_action):\n",
    "        max_index_list = []\n",
    "        max_value = state_action[0]\n",
    "        for index, value in enumerate(state_action):\n",
    "            if value > max_value:\n",
    "                max_index_list.clear()\n",
    "                max_value = value\n",
    "                max_index_list.append(index)\n",
    "            elif value == max_value:\n",
    "                max_index_list.append(index)\n",
    "        return random.choice(max_index_list)\n",
    "\n",
    "    def choose_action(self, agent_idx, state):\n",
    "        state = tuple(state)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action = np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            state_action = self.q_tables[agent_idx][state]\n",
    "            action = self.arg_max(state_action)\n",
    "        return action\n",
    "\n",
    "    def learn(self, agent_idx, state, action, reward, next_state):\n",
    "        state = tuple(state)\n",
    "        next_state = tuple(next_state)\n",
    "        current_q = self.q_tables[agent_idx][state][action]\n",
    "        max_next_q = max(self.q_tables[agent_idx][next_state])\n",
    "        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_next_q - current_q)\n",
    "        self.q_tables[agent_idx][state][action] = new_q\n",
    "\n",
    "    def adjust_q_for_successful_path(self, agent_idx, state, action, successful_path, distance_threshold=2):\n",
    "        \"\"\"\n",
    "        Adjust Q-values based on the successful path of another agent.\n",
    "        This provides a 'pull' effect towards the successful path.\n",
    "        \"\"\"\n",
    "        state = tuple(state)\n",
    "        current_q = self.q_tables[agent_idx][state][action]\n",
    "\n",
    "        # Calculate distance from current state to each state in the successful path\n",
    "        for path_state in successful_path:\n",
    "            path_state = tuple(path_state)\n",
    "            distance = np.linalg.norm(np.array(state) - np.array(path_state))\n",
    "\n",
    "            if distance <= distance_threshold:\n",
    "                # Closer states get a higher 'pull' reward\n",
    "                pull_reward = 1 / (distance + 1e-5)  # Prevent division by zero\n",
    "                new_q = current_q + self.learning_rate * (pull_reward - current_q)\n",
    "                self.q_tables[agent_idx][state][action] = new_q\n",
    "\n",
    "\n",
    "class Case:\n",
    "\n",
    "    def __init__(self, problem, solution, trust_value=0.5, total_time_steps=0, path=None):\n",
    "        self.problem = ast.literal_eval(problem) if isinstance(problem, str) else problem\n",
    "        self.solution = solution\n",
    "        self.trust_value = trust_value\n",
    "        self.total_time_steps = total_time_steps  # New attribute for total time steps\n",
    "        self.path = path  # New attribute to store the path\n",
    "\n",
    "    @staticmethod\n",
    "    def sim_q(state1, state2):\n",
    "        state1 = np.atleast_1d(state1)\n",
    "        state2 = np.atleast_1d(state2)\n",
    "        CNDMaxDist = 6\n",
    "        v = state1.size\n",
    "        DistQ = np.sum([Case.dist_q(Objic, Objip) for Objic, Objip in zip(state1, state2)])\n",
    "        similarity = (CNDMaxDist * v - DistQ) / (CNDMaxDist * v)\n",
    "        return similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def dist_q(X1, X2):\n",
    "        return np.min(np.abs(X1 - X2))\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve(state, case_base, threshold=0.1):\n",
    "        state = ast.literal_eval(state) if isinstance(state, str) else state\n",
    "        for case in case_base:\n",
    "            if state == case.problem: \n",
    "                return case\n",
    "\n",
    "    @staticmethod\n",
    "    def reuse(agent_idx, c, own_temp_case_base, comm_temp_case_base, source='own'):\n",
    "        \"\"\"Reuse step for adding cases to temporary case bases.\"\"\"\n",
    "        if source == 'own':\n",
    "            own_temp_case_base.append(c)\n",
    "        elif source == 'comm':\n",
    "            comm_temp_case_base.append(c)\n",
    "\n",
    "    @staticmethod\n",
    "    def revise(agent_idx, case_base, temporary_case_base, successful_episodes):\n",
    "        for case in case_base:\n",
    "            if any((case.problem, case.solution) == (temp_case.problem, temp_case.solution) for temp_case in temporary_case_base):\n",
    "                if successful_episodes:\n",
    "                    case.trust_value += 0.1\n",
    "                else:\n",
    "                    case.trust_value -= 0.4\n",
    "            else:\n",
    "                if successful_episodes:\n",
    "                    case.trust_value -= 0.4\n",
    "            \n",
    "            case.trust_value = max(0, min(case.trust_value, 1))\n",
    "            print(f\"case content after REVISE for agent {agent_idx}, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}, time steps: {case.total_time_steps}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def retain(agent_idx, case_base, own_temp_case_base, comm_temp_case_base, successful_episodes, threshold=0.49):\n",
    "\n",
    "        if successful_episodes:\n",
    "            for temp_case in reversed(own_temp_case_base):\n",
    "                state = tuple(np.atleast_1d(temp_case.problem))\n",
    "    \n",
    "                if not any(tuple(np.atleast_1d(case.problem)) == state for case in case_base):\n",
    "                    case_base.append(temp_case)\n",
    "                    print(f\"Episode succeeded, case {temp_case.problem} is empty. Temporary case base stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value}\")         \n",
    "                else:\n",
    "                    print(f\"Episode succeeded, case {temp_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_case.problem, temp_case.solution, temp_case.trust_value}\")    \n",
    "        else:\n",
    "            print(f\"Episode not succeeded, temporary case base from own experience is not stored to the case base\")\n",
    "        \n",
    "        case_base_dict = {tuple(np.atleast_1d(case.problem)): case for case in case_base}\n",
    "\n",
    "        for temp_comm_case in reversed(comm_temp_case_base):\n",
    "            state_comm = tuple(np.atleast_1d(temp_comm_case.problem))\n",
    "            \n",
    "            existing_case = case_base_dict.get(state_comm) \n",
    "\n",
    "            if existing_case is None:\n",
    "                case_base.append(temp_comm_case)\n",
    "                case_base_dict[state_comm] = temp_comm_case \n",
    "                print(f\"Integrated case process. comm case {temp_comm_case.problem} is empty. Temporary case base stored to the case base: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")         \n",
    "            # elif existing_case.trust_value < temp_comm_case.trust_value:\n",
    "            #     existing_case.solution = temp_comm_case.solution\n",
    "            #     existing_case.trust_value = max(0, temp_comm_case.trust_value)\n",
    "            #     print(f\"Integrated case process. Similar comm case for agent {agent_idx} is found. Updated case base with higher trust value: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")\n",
    "            # else:\n",
    "            #     print(f\"Integrated case process. comm case {temp_comm_case.problem} for agent {agent_idx} is not empty. Temporary case base that not stored to the case base: {temp_comm_case.problem, temp_comm_case.solution, temp_comm_case.trust_value}\")   \n",
    "\n",
    "        # Apply 'pull' effect: Adjust Q-values based on successful path\n",
    "        for comm_case in comm_temp_case_base:\n",
    "            if comm_case.trust_value >= threshold and comm_case.path is not None:\n",
    "                successful_path = comm_case.path\n",
    "                for state, action in QCBRL.get_states_actions_near_path(agent_idx, successful_path):\n",
    "                    agent.problem_solvers[agent_idx].adjust_q_for_successful_path(agent_idx, state, action, successful_path)\n",
    "\n",
    "        case_base[:] = [case for case in case_base if case.trust_value >= threshold]\n",
    "\n",
    "        for case in case_base:\n",
    "            print(f\"cases content after RETAIN, problem: {case.problem}, solution: {case.solution}, tv: {case.trust_value}\")\n",
    "\n",
    "        return case_base\n",
    "\n",
    "\n",
    "class QCBRL:\n",
    "    def __init__(self, num_actions, env, episodes, max_steps, alpha, gamma, epsilon, epsilon_decay, epsilon_min, render):\n",
    "        self.num_actions = num_actions\n",
    "        self.env = env\n",
    "        self.episodes = episodes\n",
    "        self.max_steps = max_steps\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.render = render\n",
    "        self.epsilon_decay = epsilon_decay  \n",
    "        self.epsilon_min = epsilon_min  \n",
    "\n",
    "        self.problem_solvers = [ProblemSolver(num_actions, self.env, alpha, gamma, epsilon) for _ in range(self.env.num_agents)]\n",
    "        self.case_bases = [[] for _ in range(self.env.num_agents)]  # Individual case bases for each agent\n",
    "        self.own_temp_case_bases = [[] for _ in range(self.env.num_agents)]  # Temporary case bases for own experiences\n",
    "        self.comm_temp_case_bases = [[] for _ in range(self.env.num_agents)]  # Temporary case bases for communication experiences\n",
    "        self.successful_episodes = [0] * self.env.num_agents\n",
    "        self.rewards_per_episode = [[] for _ in range(self.env.num_agents)]  \n",
    "        self.total_successful_episodes = 0 \n",
    "        self.action_type = 0\n",
    "\n",
    "    def run(self):\n",
    "        rewards = []\n",
    "        memory_usage = []\n",
    "        gpu_memory_usage = []\n",
    "        num_successful_episodes = 0\n",
    "        total_steps_list = []\n",
    "        success_steps = []\n",
    "\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "        for episode in range(self.episodes):\n",
    "            states = self.env.reset()\n",
    "            episode_reward = [0] * self.env.num_agents\n",
    "            total_steps = 0 \n",
    "            self.own_temp_case_bases = [[] for _ in range(self.env.num_agents)]\n",
    "            self.comm_temp_case_bases = [[] for _ in range(self.env.num_agents)]\n",
    "            success_count = [0] * self.env.num_agents\n",
    "            dones = [False] * self.env.num_agents\n",
    "            win_states = [False] * self.env.num_agents\n",
    "            successful_episodes = False\n",
    "\n",
    "            while not(all(dones)):\n",
    "                print(f\"----- starting point of Episode {episode} in steps {total_steps} loop -----\")\n",
    "                \n",
    "                actions = []\n",
    "                for agent_idx in range(self.env.num_agents):\n",
    "                    state = states[agent_idx]\n",
    "                    action = self.take_action(agent_idx, state)\n",
    "                    actions.append(action)\n",
    "\n",
    "                next_states, rewards, dones = self.env.step(actions)\n",
    "\n",
    "                win_states = []\n",
    "                for agent_idx in range(self.env.num_agents):\n",
    "                    state = states[agent_idx]\n",
    "                    action = actions[agent_idx]\n",
    "                    reward = rewards[agent_idx]\n",
    "                    next_state = next_states[agent_idx]\n",
    "\n",
    "                    physical_state = tuple(state[0])\n",
    "                    win_state = state[1]\n",
    "                    comm_state = state[2]  # Communication state containing messages from other agents\n",
    "\n",
    "                    physical_next_state = tuple(next_state[0])\n",
    "                    win_next_state = next_state[1]\n",
    "                    comm_next_state = tuple(next_state[2]) if next_state[2] != 0 else next_state[2]\n",
    "\n",
    "                    physical_action = action[0]\n",
    "                    comm_action = action[1]\n",
    "\n",
    "                    # Process messages received from other agents\n",
    "                    print(f\"comm next state for agent {agent_idx}: {comm_next_state}\")\n",
    "                    \n",
    "                    if (comm_next_state == 0):\n",
    "                        pass\n",
    "                    else:\n",
    "                        comm_case = Case(problem=comm_next_state[0], solution=comm_next_state[1], trust_value=comm_next_state[2], total_time_steps=comm_next_state[3], path=comm_next_state[4] if len(comm_next_state) > 4 else None)\n",
    "                        Case.reuse(agent_idx, comm_case, self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], source='comm')\n",
    "\n",
    "                    c = Case(physical_state, physical_action, total_time_steps=total_steps)\n",
    "                    Case.reuse(agent_idx, c, self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], source='own')\n",
    "\n",
    "                    if self.action_type == 0:\n",
    "                        print(f\"action type of agent: {agent_idx}: problem solver, agent learned\")\n",
    "                        self.problem_solvers[agent_idx].learn(agent_idx, physical_state, physical_action, reward, physical_next_state)\n",
    "\n",
    "                    if (win_next_state): \n",
    "                        success_count[agent_idx] += 1\n",
    "\n",
    "                    episode_reward[agent_idx] += reward\n",
    "                    win_states.append(win_next_state)  \n",
    "\n",
    "                states = next_states\n",
    "                total_steps += 1\n",
    "\n",
    "                self.env.render()\n",
    "                \n",
    "            if self.env.win_flag:\n",
    "                self.total_successful_episodes += 1\n",
    "                success_steps.append(total_steps)\n",
    "                successful_episodes = True\n",
    "\n",
    "            for agent_idx in range(self.env.num_agents):\n",
    "                print(f\"win status of agent {agent_idx}  before update the case base: {win_states[agent_idx]}\")\n",
    "                self.rewards_per_episode[agent_idx].append(episode_reward[agent_idx])\n",
    "\n",
    "                print(f\"agent{agent_idx} own temp case base: {self.own_temp_case_bases[agent_idx]}\")\n",
    "                print(f\"agent{agent_idx} comm temp case base: {self.comm_temp_case_bases[agent_idx]}\")\n",
    "                \n",
    "                Case.revise(agent_idx, self.case_bases[agent_idx], self.own_temp_case_bases[agent_idx], win_states[agent_idx])\n",
    "                self.case_bases[agent_idx] = Case.retain(agent_idx, self.case_bases[agent_idx], self.own_temp_case_bases[agent_idx], self.comm_temp_case_bases[agent_idx], win_states[agent_idx])\n",
    "               \n",
    "                \n",
    "            self.epsilon = max(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
    "            \n",
    "            memory_usage.append(psutil.virtual_memory().percent)\n",
    "            gpu_memory_usage.append(pynvml.nvmlDeviceGetMemoryInfo(handle).used / 1024**2)\n",
    "\n",
    "            print(f\"Episode: {episode}, Total Steps: {total_steps}, Total Rewards: {episode_reward}, Status Episode: {successful_episodes}\")\n",
    "            print(f\"------------------------------------------End of episode {episode} loop--------------------\")\n",
    "\n",
    "        success_rate = self.total_successful_episodes / self.episodes * 100\n",
    "\n",
    "        return self.rewards_per_episode, success_rate, memory_usage, gpu_memory_usage, success_steps\n",
    "\n",
    "    def take_action(self, agent_idx, state):\n",
    "        physical_state = tuple(state[0])\n",
    "        win_state = state[1]\n",
    "        comm_state = state[2]\n",
    "\n",
    "        similar_solution = Case.retrieve(physical_state, self.case_bases[agent_idx])\n",
    "        if similar_solution is not None:\n",
    "            physical_action = similar_solution.solution\n",
    "            comm_action = (similar_solution.problem, similar_solution.solution, similar_solution.trust_value, similar_solution.total_time_steps, similar_solution.path)\n",
    "            self.action_type = 1\n",
    "            print(f\"Physical Action for Agent {agent_idx} from case base: {physical_action}\")\n",
    "        else:\n",
    "            physical_action = self.problem_solvers[agent_idx].choose_action(agent_idx, physical_state)\n",
    "            comm_action = 0  # No communication action if using problem solver action\n",
    "            self.action_type = 0\n",
    "            print(f\"Physical Action for Agent {agent_idx} from problem solver: {physical_action}\")\n",
    "\n",
    "        return (physical_action, comm_action)\n",
    "\n",
    "    def case_exists_in_case_base(self, case, case_base):\n",
    "        \"\"\"Check if a case exists in the given case base.\"\"\"\n",
    "        return any(existing_case.problem == case.problem and existing_case.solution == case.solution for existing_case in case_base)\n",
    "        \n",
    "    def save_case_base_temporary(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_temporary_agent_{agent_idx}.json\"\n",
    "            case_base_data = [{\"problem\": case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem, \n",
    "                            \"solution\": int(case.solution), \n",
    "                            \"trust_value\": float(case.trust_value),\n",
    "                            \"total_time_steps\": int(case.total_time_steps),\n",
    "                            \"path\": case.path} for case in self.own_temp_case_bases[agent_idx] + self.comm_temp_case_bases[agent_idx]]\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(case_base_data, file)\n",
    "            print(f\"Temporary case base for Agent {agent_idx} saved successfully.\")\n",
    "\n",
    "    def save_case_base(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_agent_{agent_idx}.json\"\n",
    "            case_base_data = [{\"problem\": case.problem.tolist() if isinstance(case.problem, np.ndarray) else case.problem, \n",
    "                            \"solution\": int(case.solution), \n",
    "                            \"trust_value\": float(case.trust_value),\n",
    "                            \"total_time_steps\": int(case.total_time_steps),\n",
    "                            \"path\": case.path} for case in self.case_bases[agent_idx]]\n",
    "            with open(filename, 'w') as file:\n",
    "                json.dump(case_base_data, file)\n",
    "            print(f\"Case base for Agent {agent_idx} saved successfully.\")\n",
    "        \n",
    "    def load_case_base(self):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            filename = f\"cases/case_base_agent_{agent_idx}.json\"\n",
    "            try:\n",
    "                with open(filename, 'r') as file:\n",
    "                    case_base_data = json.load(file)\n",
    "                    self.case_bases[agent_idx] = [Case(np.array(case[\"problem\"]), case[\"solution\"], case[\"trust_value\"], case[\"total_time_steps\"], case.get(\"path\")) for case in case_base_data]\n",
    "                    print(f\"Case base for Agent {agent_idx} loaded successfully.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Case base file for Agent {agent_idx} not found. Starting with an empty case base.\")\n",
    "\n",
    "    def display_success_rate(self, success_rate):\n",
    "        print(f\"Success rate: {success_rate}%\")\n",
    "\n",
    "\n",
    "    def plot_rewards(self, rewards):\n",
    "        for agent_idx in range(self.env.num_agents):\n",
    "            plt.plot([reward for reward in rewards[agent_idx]], label=f'Agent {agent_idx}')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Reward')\n",
    "        plt.title('Rewards over Episodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_total_steps(self, total_steps_list):\n",
    "        plt.plot(total_steps_list)\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Total Steps')\n",
    "        plt.title('Total Steps for Successful Episodes over Episodes')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_resources(self, memory_usage, gpu_memory_usage):\n",
    "        plt.plot(memory_usage, label='Memory (%)')\n",
    "        plt.plot(gpu_memory_usage, label='GPU Memory (MB)')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Resource Usage')\n",
    "        plt.title('Resource Usage over Episodes')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_successful_path_from_case(case):\n",
    "        \"\"\"\n",
    "        Extract the successful path from a given case.\n",
    "        This can be stored as part of the case's metadata or reconstructed from the case history.\n",
    "        \"\"\"\n",
    "        return case.path if case.path is not None else []\n",
    "\n",
    "    @staticmethod\n",
    "    def get_states_actions_near_path(agent_idx, successful_path, distance_threshold=2):\n",
    "        \"\"\"\n",
    "        Find all states and actions of the agent that are near the successful path.\n",
    "        This allows us to apply the 'pull' effect more effectively.\n",
    "        \"\"\"\n",
    "        nearby_states_actions = []\n",
    "        for state in agent.problem_solvers[agent_idx].q_tables[agent_idx].keys():\n",
    "            for action in range(agent.num_actions):\n",
    "                if QCBRL.is_state_near_path(state, successful_path, distance_threshold):\n",
    "                    nearby_states_actions.append((state, action))\n",
    "        return nearby_states_actions\n",
    "\n",
    "    @staticmethod\n",
    "    def is_state_near_path(state, successful_path, threshold=2):\n",
    "        \"\"\"\n",
    "        Check if a state is near the successful path within a certain threshold.\n",
    "        \"\"\"\n",
    "        for path_state in successful_path:\n",
    "            if np.linalg.norm(np.array(state) - np.array(path_state)) <= threshold:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_agents = 2\n",
    "    num_obstacles = 3\n",
    "    obstacles_random_steps = 35\n",
    "    is_agent_silent = False\n",
    "    episodes = 100\n",
    "    max_steps = 1000\n",
    "    alpha = 0.1\n",
    "    gamma = 0.9\n",
    "    epsilon = 0.2\n",
    "    epsilon_decay = 0.995  \n",
    "    epsilon_min = 0.01  \n",
    "    render = True\n",
    "\n",
    "    env = Env(num_agents=num_agents, num_obstacles=num_obstacles, obstacles_random_steps=obstacles_random_steps, is_agent_silent=is_agent_silent)\n",
    "    \n",
    "    num_actions = len(env.action_space)\n",
    "    \n",
    "    agent = QCBRL(num_actions, env, episodes, max_steps, alpha, gamma, epsilon, epsilon_decay, epsilon_min, render)\n",
    "    rewards, success_rate, memory_usage, gpu_memory_usage, total_step_list = agent.run()\n",
    "\n",
    "    agent.display_success_rate(success_rate)\n",
    "    agent.plot_rewards(rewards)\n",
    "    agent.plot_total_steps(total_step_list)\n",
    "    agent.plot_resources(memory_usage, gpu_memory_usage)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
