{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m data_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_total_case\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (data_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_case_agent_0\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m data_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_case_agent_1\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Extract the success rate and count for the current `dec_unsuccess` value\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[43msuccess_info_summary\u001b[49m\u001b[43m[\u001b[49m\u001b[43msuccess_info_summary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdec_unsuccess\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdec_value\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuccess_count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     74\u001b[0m rate \u001b[38;5;241m=\u001b[39m success_info_summary[success_info_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdec_unsuccess\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m dec_value][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Plot the line for the current `dec_unsuccess` value\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Folder path containing CSV files in the current directory\n",
    "folder_path = './csv_nagents/'\n",
    "\n",
    "# Variable to control how many episodes to average together\n",
    "episodes_per_average = 1\n",
    "\n",
    "# Initialize an empty list to hold data from all files\n",
    "all_data_frames = []\n",
    "\n",
    "# Loop through all CSV files in the specified folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Load the data from the CSV file and append to the list\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['filename'] = filename  # Add a filename column to keep track of source\n",
    "        all_data_frames.append(df)\n",
    "\n",
    "# If no CSV files are found, exit without generating the graph\n",
    "if len(all_data_frames) == 0:\n",
    "    print(\"No CSV files found in the specified folder.\")\n",
    "else:\n",
    "    # Concatenate all data frames into a single data frame\n",
    "    combined_data = pd.concat(all_data_frames, ignore_index=True)\n",
    "\n",
    "    # Create a new column for grouping episodes in batches\n",
    "    combined_data['eps_group'] = (combined_data['eps'] // episodes_per_average) * episodes_per_average\n",
    "\n",
    "    # Group by 'eps_group' and 'dec_unsuccess', then calculate the average values for numeric columns only\n",
    "    grouped_data = combined_data.groupby(['eps_group', 'dec_unsuccess']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "    # Find unique values of 'dec_unsuccess' for coloring different lines\n",
    "    unique_dec_unsuccess_values = grouped_data['dec_unsuccess'].unique()\n",
    "\n",
    "    # Calculate the success count and total number of episodes for each `dec_unsuccess` value\n",
    "    success_count = combined_data[combined_data['eps_status'] == 1].groupby(['dec_unsuccess', 'filename']).size().reset_index(name='success_count')\n",
    "    total_episodes_info = combined_data[['dec_unsuccess', 'eps', 'filename']].drop_duplicates().groupby(['dec_unsuccess', 'filename']).size().reset_index(name='total_episodes')\n",
    "\n",
    "    # Merge success count and total episodes, and then summarize for each dec_unsuccess value\n",
    "    success_info = pd.merge(success_count, total_episodes_info, on=['dec_unsuccess', 'filename'])\n",
    "    success_info_summary = success_info.groupby('dec_unsuccess').agg({\n",
    "        'success_count': 'sum',\n",
    "        'total_episodes': 'sum',\n",
    "        'filename': 'nunique'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename 'filename' to 'num_similar_files' for clarity\n",
    "    success_info_summary.rename(columns={'filename': 'num_similar_files'}, inplace=True)\n",
    "\n",
    "    # Calculate the success count by dividing by the number of similar files\n",
    "    success_info_summary['success_count'] = success_info_summary['success_count'] / success_info_summary['num_similar_files']\n",
    "\n",
    "    # Calculate the success rate using the previous method (total success count divided by total episodes without averaging by similar files)\n",
    "    success_info_summary['success_rate'] = success_info_summary['success_count'] * success_info_summary['num_similar_files'] / success_info_summary['total_episodes']\n",
    "\n",
    "    # Plot: Average Total Cases Stored Among Agents Across All Episodes\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Define a set of colors to use for different lines\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "\n",
    "    # Plot the average total cases for each `dec_unsuccess` value\n",
    "    for i, dec_value in enumerate(unique_dec_unsuccess_values):\n",
    "        # Filter the data for the current `dec_unsuccess` value\n",
    "        data_filtered = grouped_data[grouped_data['dec_unsuccess'] == dec_value]\n",
    "        # Calculate average total cases stored among agents\n",
    "        data_filtered['avg_total_case'] = (data_filtered['total_case_agent_0'] + data_filtered['total_case_agent_1']) / 2\n",
    "        # Extract the success rate and count for the current `dec_unsuccess` value\n",
    "        count = success_info_summary[success_info_summary['dec_unsuccess'] == dec_value]['success_count'].values[0]\n",
    "        rate = success_info_summary[success_info_summary['dec_unsuccess'] == dec_value]['success_rate'].values[0]\n",
    "        # Plot the line for the current `dec_unsuccess` value\n",
    "        plt.plot(data_filtered['eps_group'], data_filtered['avg_total_case'], label=f'dec_unsuccess = {dec_value} (Success Count: {count:.0f}, Success Rate: {rate:.2f})', color=colors[i % len(colors)], marker='o')\n",
    "\n",
    "    # Set chart title and labels\n",
    "    total_episodes = combined_data['eps'].nunique()\n",
    "    plt.title(f\"Average Total Cases Stored Among Agents (Every {episodes_per_average} Episodes from Total {total_episodes} Episodes)\")\n",
    "    plt.xlabel('Grouped Episodes (eps_group)')\n",
    "    plt.ylabel('Average Total Cases Stored Among Agents')\n",
    "\n",
    "    # Place the legend above the plot area without overlapping, with a border\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=2, frameon=True, edgecolor='black')\n",
    "\n",
    "    # Extract non-graphical data for display (averaged across all files)\n",
    "    non_graphical_data = grouped_data[['inc_success', 'dec_success_nocase', 'del_threshold']].mean().to_dict()\n",
    "\n",
    "    # Combine all additional formatted information into one text block, including the number of episodes\n",
    "    legend_text = (\n",
    "        f\"Total number of episodes: {combined_data['eps'].nunique()}\\n\"\n",
    "        f\"+{non_graphical_data['inc_success']:.2f} if (successful_episodes and case exists)\\n\"\n",
    "        f\"-{non_graphical_data['dec_success_nocase']:.2f} if (successful_episodes and case does not exist)\\n\"\n",
    "        f\"Deletion Threshold: {non_graphical_data['del_threshold']:.2f}\"\n",
    "    )\n",
    "\n",
    "    # Add the combined formatted information below the plot with a single enhanced box and adjust positioning closer to the plot\n",
    "    props = dict(boxstyle='round,pad=0.5', edgecolor='black', facecolor='lightyellow', alpha=0.9, linewidth=1.5)\n",
    "    plt.figtext(0.1, -0.1, legend_text, fontsize=10, ha='left', bbox=props)\n",
    "\n",
    "    # Adjust layout to remove extra space between graph and legend\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=1)  # Adjusted the top margin to ensure there's no extra space between the legend and plot\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
